## MySQL

​		不区分大小写，默认字符检索策略为utf8_general_ci，区分大小写：utf8_general_cs、uft8_bin二进制比较。

### 组成架构

​		逻辑架构可分为服务层和存储引擎。服务层为MySQL的核心服务功能，查询语句解析、缓存、词法语句分析等。

#### 连接器

​		负责管理连接，权限的验证等。

#### 解析器

​		对输入的sql进行解析，进行词法分析，需要识别出里面的字符串代表什么意思。比如select代表查询，T代表某张表，ID代表某张表的列字段叫id。之后进行语法分析，根据语法规则，判断输入的sql语句是否符合mysql语法。

#### 优化器

​		经过解析之后，mysql就知道你需要做什么事情了。但是在真正执行之前还需要经过优化器处理。比如当表中存在多个索引的时候，选择哪个索引来使用。或者多表关联的时候，选择各个表的连接先后顺序。

#### 执行器

​		开始执行之前首先确认对该表有无执行查询的权限。如果没有，则返回错误的信息提示。如果有权限，则开始执行。

​		首先根据该表的引擎类型，使用这个引擎提供的接口。比如查询某表，然后利用某字段查找，如果没有添加索引，则调用引擎的接口取出第一行数据，判断结果是不是，如果不是，依次再调用引擎的下一行数据，直至取出这个表中所有的数据。如果该字段有索引，执行过程也大致相似。具体的数据是保存在引擎中的在Mysql中，常见的引擎有MyISAM和InnoDB。

### SQL执行过程

1. 客户端通过 TCP 连接发送连接请求到 mysql 连接器，连接器会对该请求进行权限验证及连接资源分配。
2. 建立连接后客户端发送一条语句，mysql 收到该语句后，通过命令分发器判断其是否是一条select 语句，如果是，在开启查询缓存的情况下，先在查询缓存中查找该 SQL 是否完全匹配，如果完全匹配，验证当前用户是否具备查询权限，如果权限验证通过，直接返回结果集给客户端，该查询也就完成了。如果不匹配继续向下执行。
3. 如果在查询缓存中未匹配成功，则将语句交给分析器作语法分析，MySQL 需要知道到底要查哪些东西，如果语法不对，就会返回语法错误中断查询。
4. 分析器的工作完成后，将语句传递给预处理器，检查数据表和数据列是否存在，解析别名看是否存在歧义等。
5. 语句解析完成后，MySQL 就知道要查什么了，之后会将语句传递给优化器进行优化（通过索引选择最快的查找方式），并生成执行计划。
6. 之后交给执行器去具体执行该语句，在执行之前，会先检查该用户是否具有查询权限，如果有，继续执行该语句。执行器开始执行后，会逐渐将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。

### 引擎

​		建表时指定引擎。

```
create table 表名 ( … ) engine=MyISAM default charset=utf8;
```

#### Innodb

1. 支持外键，需有主键。如果我们定义了主键，那么InnoDB会选择主键作为聚集索引。
2. 支持事务，每条SQL语句都将自动封装成事务，自动提交，影响速度。
3. 支持表锁和行锁（默认），行锁由索引实现，若没有命中索引，则依然会使用表锁。但行锁和表锁的同时存在会发生冲突，如A申请了行共享锁，而B 再申请表互斥锁。这时 B 不仅需要查看是否已经存在其他表锁，以及逐个查看是否存在行锁，效率太低。于是又引入了意向锁。意向锁是一种表级锁，用来指示接下来的一个事务将要获取的是共享锁或者独占锁。
4. 不保存表的行数，查询某张表的行数会进行全表扫描。
5. 聚集索引，即数据文件和索引绑在一起，数据本身按索引形式来存储，为B+树结构。.frm 表结构文件、.ibd 数据文件。
6. 适合写密集、高并发。

##### 主键

​		如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一列作为主键。如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引（ROWID随着行记录的写入而主键递增，这个ROWID不像ORACLE的ROWID那样可引用，是隐含的）。所以Innodb表最好要设置主键。

​		最好使用自增整数作为主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，即页面达到装载因子（InnoDB默认为15/16），就会自动开辟一个新的页。

​		如果采用UUID等非自增主键，那么插入的位置是不固定的，可能靠前，也可能靠后，后面再次插入进来，很有可能会导致原先的节点重新分裂。频繁的移动、分页操作增加开销，且造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。

#### myisam

1. 不支持外键，可以没有主键。
2. 不支持事务
3. 支持表锁
4. 保存整个表的行数，执行速度很快。适合做很多count计算，但where筛选无效。
5. 非聚集索引，即索引和数据文件分开存储。.frm 表结构文件、.MYD 数据文件、.MYI 索引文件。索引文件中存放对应数据的文件指针，接着会去MYD数据文件中去找对应指针的数据。
6. 适合读密集。

### 索引

​		索引是可以帮助mysql高效获取数据的数据结构。未添加索引时，MySQL需从磁盘中遍历全表去查找某条记录。添加索引后，MySQL从索引文件中取出某条数据对应的磁盘地址，从磁盘中取出该条数据。

#### 优缺点

​		数据索引的存储是有序的，在有序的情况下，通过索引查询一个数据是无需遍历索引记录的。极端情况下，数据索引的查询效率为二分法查询效率，趋近于 log2(N)。适当的使用索引可以提高数据检索速度，也可以降低数据库的IO成本，并且索引还可以降低数据库的排序成本。排序分组操作主要消耗的就是CPU资源和内存，所以能够在排序分组操作中好好的利用索引将会极大地降低CPU资源的消耗。可以给经常需要进行查询的字段创建索引。

​		创建索引和维护索引需要耗费时间，索引需要占用空间，进行数据的增删改时候需要动态维护索引。

#### 实现原理

#### 数据结构

##### 磁盘I/O

​		磁盘由盘片组成。盘片有两面，称之为盘面surface。盘面上覆盖磁性材料。中间是一个可以旋转的轴Spindle，使得整个盘面能够旋转。每个盘面又由一系列的同心圆组成，称之为磁道track。磁道又被划分为一组组扇区sector。扇区的大小大概都相等，为512字节。

​		当从磁盘中读取数据时，利用读写头找到对应的磁道，这个步骤称之为寻道。找到磁道后，盘片开始转动，磁道上的每个位都可以被磁头感知到，然后读取到其内容，

​		对磁盘的访问整个过程可以分为寻道时间和访问时间。一般情况下，寻道时间较慢。由于磁盘存取的速度比内存慢很多，所以磁盘读取时，通常情况下并不是按需读取，而是会预读一部分数据。预读的长度通常情况下为一个页的整数倍。一个页一般情况下大小为4k。也就是说一次磁盘IO通常只会读取4k的几倍。

​		索引本身很大，因此索引以索引表的形式存储在磁盘中，无法一次将全部索引加载到内存中，每次只能从磁盘中读取一个页到内存中。这样的话，索引查找过程中就要产生磁盘 I/O 消耗，相对于内存存取，I/O 存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘 I/O 操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘 I/O 的存取次数。

​		把全部数据写入到一个节点中，也并没有太大用处，因为一般只会读取4k或者4k的几倍。数据库的实现者也利用磁盘预读的这一点，将一个节点的大小设为4k或者4k的几倍。最好的状态是一次磁盘IO就把一个节点里全部数据给读取到内存中了。这样盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。

##### 二叉树

​		底层实现是数组，逻辑上相邻的节点在物理结构上可能相差很远。当数据量非常大时，树的深度非常深，树越深，硬盘和内存的交互次数将越多。硬盘和内存的交互速度慢，交互次数越多，则查询越慢。磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存，二叉树没能充分利用磁盘预读功能。

##### hash表

​		采用一定的哈希算法，把键值换算成新的哈希值，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。缺点：

1. hash索引仅能查找=、in等查找，无法进行范围查找。
2. 无法利用索引的数据来避免任何排序运算。
3. 存在哈希碰撞问题。当数据量多的时候，不可避免的会出现很多数据重复堆叠在同一个下标，仍需遍历该下标下的所有元素。
4. 不支持联合索引的最左前缀匹配规则。

​		常用的 InnoDB 引擎中默认使用的是B+树索引，它会实时监控表上索引的使用情况。如果认为建立哈希索引可以提高查询效率，则自动在内存中的“自适应哈希索引缓冲区”建立哈希索引（在InnoDB中默认开启自适应哈希索引）。通过观察搜索模式，MySQL会利用index key的前缀建立哈希索引，如果一个表几乎大部分都在缓冲池中，那么建立一个哈希索引能够加快等值查询。

​		在某些工作负载下，通过哈希索引查找带来的性能提升远大于额外的监控索引搜索情况和保持这个哈希表结构所带来的开销。但某些时候，在负载高的情况下，自适应哈希索引中添加的read/write锁也会带来竞争，比如高并发的join操作。like操作和%的通配符操作也不适用于自适应哈希索引，可能要关闭自适应哈希索引。

​		在HEAP表中，如果存储的数据重复度很低（也就是说基数很大），对该列数据以等值查询为主，没有范围查询、没有排序的时候，特别适合采用哈希索引，例如这种SQL：

```
//仅等值查询
select id, name from table where name='李明'; 
```

##### B-Tree

​		多路平衡查找树，m阶的B树，每个节点可以存储多个关键字。将节点大小设置为磁盘页的大小，充分利用了磁盘预读的功能。每次读取磁盘页时就会读取一整个节点，也正因每个节点存储着非常多个关键字，有效降低了树的高度，进而要执行的磁盘读取操作次数就会非常少，更多的是在内存中对读取进来的数据进行查找。

​		每个节点最多有m-1个key，至少2个key。每个节点最多m个孩子节点，n个key的节点有n+1个指针。非根节点包含的key个数满足：m/2向上取整-1<=j<=m-1。每个节点都是按照从小到大的顺序排列，所有叶子节点位于同一层。数据查询次数不稳定。

​		一次磁盘IO，即内存和磁盘间的数据交互，一次最多只会读写4k或4k的几倍。所以将节点的大小设置为4k左右，一次将一整个节点的数据读取进去。B树每个key都有对应的数据，增加了数据量的大小。每个key和data占用的空间越多，能存储的key的个数便越少。若节点大小相同的情况下，一个key和value占用了1k，则一个节点只能存4个key。引入B+树。

##### B+Tree

​		B+树是B树的变种，一个平衡的多叉树，从根节点到每个叶子节点的高度差值不超过1，而且同层级的节点间有指针相互链接，是有序的。非叶子节点不存储data，只存储key，便可以存储更多的key，即阶数会显著增加。把非叶子节点的key做适当的冗余，在最终的叶子节点内存储一份完整的key和对应的data。

​		每个父节点都会出现在子节点中，父节点是子节点中的最大或最小元素。所有叶子节点都有一个指针，指向下一个数据，形成链表。由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当，B+-tree的查询效率更加稳定，每次查询的次数都是树的高度。

​		通常，B+树索引结构适用于绝大多数场景。

​		B+树有主键索引和辅助索引。主键索引按照表中主键的顺序构建一颗 B+树，并在叶节点中存放表中的行记录数据，一个表只能有一个主键索引。辅助索引，叶节点并不存储行记录数据，仅仅是主键，通过辅助索引查找到对应的主键，最后在聚集索引中使用主键获取对应的行记录。

#### 类型

##### 聚集索引

​		主键索引。每张表的主键构造一棵 B+树，叶子节点中存放整张表的行记录数据。该索引中键值的逻辑顺序即为表中相应行数据的物理存储顺序。一个表只能包含一个聚集索引。辅助索引的叶子节点存储数据的主键键值。

​		聚集索引对于那些经常要搜索范围值的列特别有效。使用聚集索引找到包含第一个值的行后，便可以确保包含后续索引值的行在物理相邻。例如，如果应用程序执行的一个查询经常检索某一日期范围内的记录，则使用聚集索引可以迅速找到包含开始日期的行，然后检索表中所有相邻的行，直到到达结束日期。这样有助于提高此类查询的性能。同样，如果对从表中检索的数据进行排序时经常要用到某一列，则可以将该表在该列上聚集（物理排序），避免每次查询该列时都进行排序，从而节省成本。

​		当索引值唯一时，使用聚集索引查找特定的行也很有效率。例如，使用唯一雇员 ID 列 emp_id 查找特定雇员的最快速的方法，是在 emp_id 列上创建聚集索引或 PRIMARY KEY 约束。

##### 非聚集索引

 		也叫辅助索引。主键B+树在叶子节点存储指向行数据的指针，即主键。目录与数据分开，索引顺序与数据物理存储顺序无关，通过辅助索引查找到对应的主键，最后在聚集索引中使用主键获取对应的行记录。主键索引和辅助索引一样。

##### 联合索引

​		建了一个(a,b,c)的复合索引，实际等于建了(a),(a,b),(a,b,c)三个索引。

###### 优缺点

1. 利用覆盖索引，避免回表，直接通过遍历索引取得数据。减少了很多的随机io操作。减少io操作，特别是随机io其实是dba主要的优化策略。覆盖索引是主要的提升性能的优化手段之一。

    ```
    //索引id
    select id from user//不用回表，直接从索引中读取id的值。
    select id,name from user//不能返回除id列其他的值，需要回表。
    
    //联合索引(id,name)
    select id from user//避免回表，不用单独建立id列的单列索引。
    select id,name from user//避免回表
    ```

2. 两个单列查询返回行较多，同时查返回行较少，使用联合索引更高效。索引列越多，通过索引筛选出的数据越少，效率更高。

3. 多一个索引，都会增加写操作的开销和磁盘空间的开销，对于大量数据的表，这是不小的开销。

覆盖索引。同样的有复合索引（a,b,c），如果有如下的sql: select a,b,c from table where a=1 and b = 1。那么MySQL可以，而无需回表，这



###### 最左前缀原则

​		联合索引指的是对多列创建了索引。比如对a，b，c创建了一个联合索引，其实相当于创建了a单列索引、（a，b）联合索引以及（a，b，c）联合索引。如果查询条件精确匹配联合索引的左边连续一列或者多列，则查询命中索引。一般把频率最高的列放在最左边。

```
//联合索引（a,b,c）
select a,b,c where b=?;
//where条件没有利用到索引，但abc均在索引树上，则仍会利用到索引。
```

#### 建立

1. 应当考虑表空间和磁盘空间是否足够。索引也是一种数据，在建立索引的时候势必也会占用大量表空间。因此在对一大表建立索引的时候首先应当考虑的是空间容量问题。
2. 在对建立索引的时候要对表进行加锁，因此应当注意操作在业务空闲的时候进行。

##### 适合建索引

1. 较频繁地作为查询条件在where或order by语句中出现的字段。单纯的 order by 不会用到索引，但如果在 where 中出现，就可以用索引了。
2. 查询中与其他表关联的字段，外键关系建立索引。
3. 用于聚合函数的列可以建立索引，例如max(column_1)或者 count(column_1)的 column_1。

##### 不适合建索引

1. 表记录太少。
2. 经常插入、删除、修改的表。
3. 数据大量重复且分布平均的字段，假如一个表有10万行记录，比如性别可能就只有两个值，建索引不仅没什么优势，还会影响到更新速度，这被称为过度索引 。
4. 经常和主字段一块查询但主字段索引值比较多的表字段。如电费实收表经常按收费序号、户标识编号、抄表日期、电费发生年月、操作 标志来具体查询某一笔收款的情况，如果将所有的字段都建在一个索引里那将会增加数据的修改、插入、删除时间，从实际上分析一笔收款如果按收费序号索引就已 经将记录减少到只有几条，如果再按后面的几个字段索引查询将对性能不产生太大的影响。
5. 唯一性太差的字段不适合建立索引
6. 更新太频繁地字段不适合创建索引
7. 不会出现在where条件中的字段不该建立索引

#### 优化

1. 使用短索引（又叫前缀索引）来优化索引。
2. 存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。范围列可以用到索引（联合索引必须是最左前缀），但是范围列后面的列无法用到索引，索引最多用于一个范围列，如果查询条件中有两个范围列则无法全用到索引。
3. 利用覆盖索引来进行查询操作，避免回表。

##### 覆盖索引

​		如果一个索引包含（或者说覆盖）所有需要查询的字段的值，则称为覆盖索引。在 InnoDB 存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要回表，也就是要通过主键再查找一次，这样就会比较慢。覆盖索引就是把要查询出的列和索引是对应的，不做回表操作。InnoDB 存储引擎支持覆盖索引，即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。SQL 只需要通过索引就可以返回查询所需要的数据，而不必通过二级索引查到主键之后再去表里查询数据。

解释一： 就是 select 的数据列只用从索引中就能够取得，不必从数据表中读取，换句话说查询列要
被所使用的索引覆盖。
解释二： 索引是高效找到行的一个方法，当能通过检索索引就可以读取想要的数据，那就不需要
再到数据表中读取行了。如果一个索引包含了（或覆盖了）满足查询语句中字段与条件的数据就叫
做覆盖索引。
解释三：是非聚集组合索引的一种形式，它包括在查询里的 Select、Join 和 Where 子句用到的所有
列（即建立索引的字段正好是覆盖查询语句[select 子句]与查询条件[Where 子句]中所涉及的字段，
也即，索引包含了查询正在查找的所有数据）。

#### 失效

1. 当对索引的列作出操作时。

    ```
    where left(name,1) = '张三'
    ```

2. where子句使用!=或<>时

3. 联合索引中有字段使用了范围查询时，语句中该字段后面的索引将失效。

    ```
    explain select * from student where age > 1 and name = '王五';
    //联合索引为(name,age)。age使用了范围，即使name是联合索引中的最左索引，也失效。
    ```

4. is null 或 is not null

5. like模糊查询时，以通配符开头会导致索引失效。可用ElasticSearch搜索引擎工具。

6. 字符串不加单引号会导致类型转换，进而导致索引失效。

7. like已 （解决方法：使用覆盖索引）

8. 用or来连接索引会失效。

#### 语法

查看某张表的索引：show index from 表名；

创建普通索引：alter table 表名 add index 索引名(索引列);

创建复合索引：alter table 表名 add index 索引名(索引列1，索引列2);

删除某张表的索引：drop index 索引名 on 表名;

#### explain

​		explain你的select查询，可以模拟优化器执行sql语句，从而知道Mysql是如何处理sql的、索引主键被如何利用的，即可分析查询语句或是表结构的性能瓶颈。

**id**：select的编号，有几个select就有几个id值。id越大表示执行的优先级越高，越先执行；id相同则依次从上向下执行。在Mysql中select查询分为简单查询（SIMPLE）和复杂查询（PRIMARY）。复杂查询又分为：简单子查询、派生表（from语句的子查询）、union查询。

**table**：这一行explain正在访问的哪张表。当有 union 时，UNION RESULT 的 table 列的值为<union1,2>，1和2表示参与 union 的 select 行id。

**select_type**：每个select子句的类型

1. SIMPLE：简单查询，未使用子查询和union等查询。
2. PRIMARY：查询中如果包含子查询，那么最外层的查询叫做PRIMARY。也叫做主查询。查询的主体。
3. SUBQUERY：select中的子查询
4. UNION：union中的后面或者第二个select语句
5. UNION RESULT：union的结果
6. SUBQUERY：子查询中的第一个SELECT，结果不依赖于外部查询。
7. DERIVED：派生表的 SELECT, FROM 子句的子查询。

**type**：表示关联类型或访问类型，即MySQL决定如何查找表中的行，查找数据行记录的大概范围。依次从最优到最差分别为： null > system > const > eq_ref > ref > range > index > ALL。一般来说，得保证查询达到range级别，最好达到ref。

1. null：MySQL 在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。
2. system：system 是 const 类型的特例，当查询的表只有一行的情况下，使用 system。
3. const：当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量
4. eq_ref：唯一性索引。返回的数据具有唯一性。主要用在联表查询中使用primary key或unique key作为关联条件的情况。
5. ref：非唯一性索引，对于每个索引键的查询，返回匹配的所有行数据。即哪些列或常量被用于查找索引列上的值。
6. range：检索指定范围的行，where条件后面是一个范围查询，比如，between、>、<等。
7. index：遍历所有索引树。
8. all：遍历全部的数据。

**possible_keys**：显示可能使用哪些索引来查找，不一定被使用。Explain出现possible_keys有列，而key显示null情况，因为表数据不多，mysql认为索引对此查询帮助不大，选择全表扫描。

**key**：显示mysql实际选择哪个索引来优化该表的访问。

**key_len**：显示mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。

**ref**：表示当前表在利用Key列记录中的索引进行查询时所用到的列或常量。

**rows**：表示mysql通过索引的统计信息，预算出来的所需要读取的行数，但是需要注意的是rows的值仅仅是统计学上的一个数据，并不是十分的准确。

**xtra:** 含 MySQL 解决查询的详细信息，有以下几种情况：

1. Using where：不用读取表中所有信息，仅通过索引就可以获取所需数据，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示 mysql 服务器将在存储引擎检索行后再进行过滤。
2. Using temporary：表示 MySQL 需要使用临时表来存储结果集，常见于排序和分组查询，常见 group by ; order by。
3. Using filesort：当 Query 中包含 order by 操作，而且无法利用索引完成的排序操作称为“文件排序。
4. Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。
5. Impossible where：这个值强调了 where 语句会导致没有符合条件的行（通过收集统计信息不可能存在结果）。
6. Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行，
7. No tables used：Query 语句中使用 from dual 或不含任何 from 子句。

### 锁机制

三种并发控制机制：

1. 悲观并发控制：锁
2. 乐观并发控制：乐观锁.
3. 多版本并发控制：MVCC多版本并发控制机制，可以与前两者中的任意一种机制结合使用，以提高数据库的读性能。

#### 乐观锁

​		 总是认为不会产生并发问题，每次去取数据的时候总认为不会有其他线程对数据进行修改，因此不会上锁，先访问数据，在更新时再判断其他线程在这之前有没有对数据进行修改。数据库不自带，一般会使用版本号机制或CAS操作实现。

##### 实现

###### 版本号实现

​		一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。

###### CAS实现

​		即compare and swap 或者 compare and set，涉及到三个操作数，数据所在的内存值，预期值，新值。当需要更新时，判断当前内存值与之前取到的值是否相等，若相等，则用新值更新，若失败则重试，一般情况下是一个自旋操作，即不断的重试。

##### 使用

例如：

​		在需要的记录表中加上version字段，每做一次update都要让version+1，所以在修改某一条记录前先读取该条记录的version记为v，在执行update时加上where version = v，如果期间有其他的线程修改了这条记录，必然导致where条件不成立，这样重复这一操作知道成功执行修改操作。

​		假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。当需要对账户信息表进行更新的时候，需要首先读取version字段。操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。

​		操作员 A 完成了修改工作，提交更新之前会先看数据库的版本和自己读取到的版本是否一致，一致的话，就会将数据版本号加1（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。

​		操作员 B 完成了操作，提交更新之前会先看数据库的版本和自己读取到的版本是否一致，但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，而自己读取到的版本号为1 ，不满足 “ 当前最后更新的version与操作员第一次读取的版本号相等 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。

​		这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。

#### 悲观锁

​		总是假设最坏的情况，每次取数据时都认为其他线程会修改，所以都会加锁（读锁、写锁、行锁等），当其他线程想要访问数据时，都需要阻塞挂起。可以依靠数据库实现，如行锁、读锁和写锁等，都是在操作之前加锁，在Java中，synchronized的思想也是悲观锁。按照锁的粒度分为表级锁和行级锁。

##### 行锁

​		只针对当前操作的行进行加锁。

优点：

1. 当在许多线程中访问不同的行时只存在少量锁定冲突。
2. 回滚时只有少量的更改
3. 可以长时间锁定单一的行。
4. 加锁粒度最小，并发度高。

 缺点：

1. 比页级或表级锁定占用更多的内存。
2. 当在表的大部分中使用时，比页级或表级锁定速度慢，因为你必须获取更多的锁。加锁的开销也最大，加锁慢，会出现死锁。
3. 如果你在大部分数据上经常进行GROUP BY操作或者必须经常扫描整个表，比其它锁定明显慢很多。

##### 表锁

​		对当前操作的整张表加锁,实现简单，加锁快，不死锁，但并发能力低。

##### Next-Key Lock

​		MySQL InnoDB 默认支持可重复读，使用了 Next-Key Lock 算法避免了幻读的发生。锁定索引项本身和索引范围。NK 是一种记录锁和间隙锁的组合锁。既锁住行，也锁住间隙。即 Record Lock 和 Gap Lock 的结合。可解决幻读问题。

##### Record Lock 记录锁

​		锁住某一行，如果表存在索引，那么记录锁是锁在索引上的，如果表没有索引，那么 InnoDB 会创建一个隐藏的聚簇索引加锁。

##### Gap LocK 间隙锁

​		间隙锁是一种记录行与记录行之间存在空隙或在第一行记录之前或最后一行记录之后产生的锁。间隙锁可能占据的单行，多行或者是空记录。 对索引项之间的“间隙”加锁，锁定记录的范围,不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。

##### 读锁

​		Share Locks，又被称为共享锁，其他用户可以并发读取数据，但任何事务都不能获取数据上的排他锁，直到已释放所有共享锁。

##### 写锁

​		Exclusive lock，排它锁，也叫X锁。若事务 T 对数据对象 A 加上 X 锁，则只允许 T 读取和修改 A，其它任何事务都不能再对 A 加任何类型的锁，直到 T 释放 A 上的锁。

##### 意向锁

​		表级锁。在意向锁存在的情况下，事务 A 必须先申请表的意向共享锁，成功后再申请一行的行锁。而事务 B发现表上有意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务 B 申请表的写锁会被阻塞。而且，申请意向锁的动作是数据库自动完成的，不需要我们手动申请。

###### 意向共享锁

​		IS。事务打算给数据行加共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS 锁。

###### 意向排他锁

​		IX。事务打算给数据行加排他锁，事务在给一个数据行加排他锁前必须先取得该表的

#### MVCC

​		Multiversion Concurrency Control，多版本控制。指的是一种提高并发的技术。最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了 InnoDB 的并发度。
​		每一个写操作都会创建一个新版本的数据，读操作会从有限多个版本的数据中挑选一个最合适的结果直接返回。在这时，读写操作之间的冲突就不再需要被关注，而管理和快速挑选数据的版本就成了 MVCC 需要解决的主要问题。
​		各数据库中 MVCC 实现并不统一，MVCC 只在 READ COMMITTED 和 REPEATABLE READ两个隔离级别下工作。对于使用 InnoDB 存储引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列：trx_id事务ID、roll_pointer上个版本指针，其实还有一个 row_id 的隐藏列但这里用不着。每次对记录进行改动，都会把对应的事务id 赋值给 trx_id 隐藏列，也会把旧的版本写入到 undo 日志中。

​		所以在并发情况下，一个记录可能存在多个版本，通过 roll_pointer 形成一个版本链。MVCC 的核心任务就是：判断一下版本链中的哪个版本是当前事务可见的。这就有了 ReadView 的概念，这个ReadView 中主要包含当前系统中还有哪些活跃的读写事务，把它们的事务 id 放到一个列表中，我们把这个列表命名为为 m_ids；根据 ReadView 的活跃事务 ID 列表和版本链事务 ID 进行比较找出可见的事务 ID 最大的版本：

1. 如果版本的 trx_id 属性值小于 m_ids 列表中最小的事务 id，表明生成该版本的事务在生成
    ReadView 前已经提交，所以该版本可以被当前事务访问。
2. 如果版本的 trx_id 属性值大于 m_ids 列表中最大的事务 id，表明生成该版本的事务在生成
    ReadView 后才生成，所以该版本不可以被当前事务访问。
3. 被访问版本的 trx_id 属性值在 m_ids 列表中最大的事务 id 和最小事务 id 之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。

​        多版本并发控制指的就是在使用 READ COMMITTD、REPEATABLE READ 这两种隔离级别的事务在执行普通的 SEELCT 操作时访问记录的版本链的过程，这样子可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。READ COMMITTD、REPEATABLE READ 这两个隔离级别的一个很大不同就是生成 ReadView 的时机不同，READ COMMITTD 在每一次进行普通 SELECT操作前都会生成一个 ReadView，而 REPEATABLE READ 只在第一次进行普通 SELECT 操作前生成一个 ReadView，之后的查询操作都重复这个 ReadView 就好了。

#### 死锁

##### 处理方式

1. 等待，直到超时，事务自动回滚。
2. 发起死锁检测， 回滚一个事务，让其他事务执行。

##### 检测

1. 构建一个以事务为起点，锁为边的有向图，看是否存在环。

### 复制/同步

#### 主从复制

​		MySQL主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。MySQL自带主从复制功能。

##### 原理

​		MySQL主从复制的基础是主服务器对数据库修改记录二进制日志，把主库的二进制日志文件 binlog复制到从库上，然后从库在本地完全顺序的执行日志中的各种操作。

##### 过程

1. 主节点 log dump 线程：当从节点连接主节点时，主节点会创建一个 log dump 线程，用于发送 bin-log 的内容。在读取 bin-log 中的操作时，此线程会对主节点上的 bin-log 加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。
2. 从节点I/O线程：当从节点上执行`start slave`命令之后，从节点会创建一个 I/O 线程用来连接主节点，请求主库中更新的 bin-log。I/O线程根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点，返回信息中除了日志所包含的信息之外，还包括本次返回的信息的bin-log position。接收到主节点 bin log dump 进程发来的更新之后，保存在本地 relay-log 中。并将读取到的 binary log 文件名和位置保存到 master-info 文件中。
3. 从节点 SQL 线程：SQL 线程负责读取 relay log 中的内容，检测到新增了内容后，解析成具体的操作并执行，最终保证主从数据的一致性。

##### 复制模式

###### 异步复制

​		默认采用异步复制方式，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，主节点不会主动 push bin log 到从节点。这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。

###### 半同步模式 

​		mysql semi-sync。这种模式下主节点只需要接收到其中一台从节点的返回信息，就会commit；否则需要等待直到超时时间然后切换成异步模式再提交；这样做的目的可以使主从数据库的数据延迟缩小，可以提高数据安全性，确保了事务提交后，binlog至少传输到了一个从节点上，不能保证从节点将此事务更新到db中。性能上会有一定的降低，响应时间会变长。半同步模式不是 mysql 内置的，需要装插件开启半同步模式。

###### 全同步模式

​		全同步模式是指主节点和从节点全部执行了 commit 并确认才会向客户端返回成功。	

##### 作用

1. 读写分离，提高性能和并发能力。随着系统中业务访问量的增大，如果是单机部署数据库，就会导致I/O访问频率过高。有了主从复制，增加多个数据存储节点，将负载分布在多个从节点上，降低单机磁盘I/O访问的频率，提高单个机器的I/O性能。
2. 及实时备灾，用于故障切换。一般会让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作；从库可以实时从主库进行复制，这样就可以做数据的热备。

##### 问题

1. 主库宕机后数据可能会丢失。采用半同步复制解决数据丢失问题。
2. 主库写压力大时，复制可能会有延迟。采用并行复制解决从库复制延迟的问题。
3. 读写分离造成的过期读问题。解决方案为对查询请求进行分类，对于必须要拿到最新结果的请求，强制将其发送给主库。或者主库更新后，从库读之前先sleep一下，类似于执行一条`select sleep(1)`命令。

##### binlog记录格式

1. 基于 SQL 语句的复制：记录会修改数据的 sql 语句到 binlog 中，减少了 binlog日志量，节约 IO，提高性能。某些情况会导致主从节点中数据不一致。
2. 基于行的复制：将 SQL 语句分解为基于 Row 更改的语句并记录在 bin log 中，也就是只记录哪条数据被修改了，修改成什么样。优点是解决了特定情况下的存储过程、或者函数、或者 trigger 的调用或者触发无法被正确复制的问题。缺点是日志量太大。
3. 混合方式：能语句就语句，不能语句就切换行

### 拆分

​		阿里《Java开发手册》提出单表行数超过500w或单表容量超过2G，推荐使用分库分表。因为MySQL单表性能瓶颈在500w左右，具体与表结构设计和机器配置有关。

#### 分库

​		使用mycat或sharing-JDBC等中间件作为数据库的代理。

#### 分表

​		单表业务量过大，可采用按业务分表或按时间分表等手段将一张表分解成多张不同的表。分区从逻辑上来讲只有一张表，而分表则是将一张表分解成多张表。

#### 表分区

​		表分区，是指根据一定规则，将数据库中的一张表分解成多个更小的，容易管理的部分。从逻辑上看，只有一张表，但是底层却是由多个物理分区组成。

​		输入命令：`show variables like '%partition%'` ，若have_partintioning 的值为YES，则表示当前MySQL支持分区。

##### 类型

**RANGE分区**：这种模式允许将数据划分不同范围。例如可以将一个表通过年份划分成若干个分区。

**LIST区**：这种模式允许系统通过预定义的列表的值来对数据进行分割。按照List中的值分区，与RANGE的区别是，range分区的区间范围值是连续的。

**HASH分区**：这中模式允许通过对表的一个或多个列的Hash Key进行计算，最后通过这个Hash码不同数值对应的数据区域进行分区。例如可以建立一个对表主键进行分区的表。

**KEY分区**：上面Hash模式的一种延伸，这里的Hash Key是MySQL系统产生的。

##### 好处

1. 存储更多数据。分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备。和单个磁盘或者文件系统相比，可以存储更多数据。

2. 优化查询。在where语句中包含分区条件时，可以只扫描一个或多个分区表来提高查询效率；涉及sum和count语句时，也可以在多个分区上并行处理，最后汇总结果。
3. 易维护。例如：想批量删除大量数据可以清除整个分区。
4. 避免某些特殊的瓶颈。例如InnoDB的单个索引的互斥访问，ext3问价你系统的inode锁竞争等。

##### 限制

1. 一个表最多只能有1024个分区。
2. MySQL5.1中，分区表达式必须是整数，或者返回整数的表达式。在MySQL5.5中提供了非整数表达式分区的支持。
3. 如果分区字段中有主键或者唯一索引的列，那么多有主键列和唯一索引列都必须包含进来。即：分区字段要么不包含主键或者索引列，要么包含全部主键和索引列。
4. 分区表中无法使用外键约束
5. MySQL的分区适用于一个表的所有数据和索引，不能只对表数据分区而不对索引分区，也不能只对索引分区而不对表分区，也不能只对表的一部分数据分区。

### 优化

#### 查询缓慢原因

1. 没有索引或者没有用到索引(这是查询慢最常见的问题，是程序设计的缺陷)
2. I/O吞吐量小，形成了瓶颈效应。
3. 没有创建计算列导致查询不优化。
4. 内存不足，网络速度慢。
5. 查询出的数据量过大（可以采用多次查询，其他的方法降低数据量）
6. 锁或者死锁(这也是查询慢最常见的问题，是程序设计的缺陷)
7. 返回了不必要的行和列
8. 查询语句不好，没有优化。

#### 查询优化

1. 升级硬件
2. 把数据、日志、索引放到不同的I/O设备上，增加读取速度。
3. 纵向、横向分割表，减少表的尺寸。
4. 选择正确的存储引擎
5. DB Server 和APPLication Server 分离
6. 开启查询缓存，优化查询。
7. Prepared Statements，一种运行在后台的SQL语句集合，可以检查一些绑定好的变量，这样可以保护程序不会受到“SQL注入式”攻击。
8. 对查询进行优化，为频繁搜索的字段建索引，尽量避免全表扫描。
9. 根据查询条件，优化SQL语句。

#### 千万级大表优化

​		任何优化，首先都需要了解你的业务和数据。QPS要到多少、带宽及存储是否足够、读写比例、HA需要做到什么程度，不同场景有不同的侧重。

##### 表设计

​		设计阶段就需要预计QPS及数据规模，参考业务场景对数据的要求，合理设计表结构，甚至违反设计范式做到适当冗余，合理建索引。

1. 数据库字段/类型定义：
    1. 经常需要计算和排序等消耗CPU的字段,应该尽量选择更为迅速的字段，如用TIMESTAMP（4个字节）代替Datetime（8个字节），通过整型替代浮点型和字符型。
    2. 变长字段使用varchar，不要使用char。
    3. 对于二进制多媒体数据，流水队列数据(如日志)，超大文本数据不要放在数据库字段中。
    4. 业务逻辑执行过程必须读到的表中必须要有初始的值，避免业务读出为负或无穷大的值导致程序失败。
    5. 并不需要一定遵守范式理论，适度的冗余，让Query尽量减少Join。

2. 索引：
    1. 合理使用索引，避免全表扫描。
    2. 业务需要的相关索引是根据实际的设计所构造sql语句的where条件来确定的，业务不需要的不要建索引，不允许在联合索引（或主键）中存在多余的字段。
    3. 唯一确定一条记录的一个字段或多个字段要建立主键或者唯一索引，不能唯一确定一条记录，为了提高查询效率建普通索引。
    4. 业务使用的表，有些记录数很少，甚至只有一条记录，为了约束的需要，也要建立索引或者设置主键。
    5. 对于取值不能重复，经常作为查询条件的字段，应该建唯一索引(主键默认唯一索引)，并且将查询条件中该字段的条件置于第一个位置。没有必要再建立与该字段有关的联合索引。
    6. 对于经常查询的字段，其值不唯一，也应该考虑建立普通索引，查询语句中该字段条件置于第一个位置，对联合索引处理的方法同样。
    7. 业务通过不唯一索引访问数据时，需要考虑通过该索引值返回的记录稠密度，原则上可能的稠密度最大不能高于0.2，如果稠密度太大，则不合适建立索引了。
    8. 需要联合索引(或联合主键)的数据库要注意索引的顺序。SQL语句中的匹配条件也要跟索引的顺序保持一致。
    9. 索引的顺势不正确也可能导致严重的后果。
    10. 表中的多个字段查询作为查询条件，不含有其他索引，并且字段联合值不重复，可以在这多个字段上建唯一的联合索引，假设索引字段为 (a1,a2,...an),则查询条件(a1 op val1,a2 op val2,...am op valm)m<=n,可以用到索引，查询条件中字段的位置与索引中的字段位置是一致的。
    11. 遵循联合索引的建立原则。
    12. 重要业务访问数据表时，但不能通过索引访问数据时，应该确保顺序访问的记录数目是有限的，原则上不得多于10。

##### 引擎

1. 若是指创建好的表，不能变动表结构的话，建议使用InnoDB引擎，多利用点内存，减轻磁盘IO负载，因为IO往往是数据库服务器的瓶颈。
2. 若索引已创建的较好了，优先考虑修改类SQL语句，使他们更快些。
3. 若是读为主，可以考虑打开query_cache，以及调整一些参数值：sort_buffer_size、read_buffer_size、read_rnd_buffer_size、join_buffer_size
4. 一般情况可以选择MyISAM存储引擎，如果需要事务支持必须使用InnoDB存储引擎。

##### 查询语句

1. 合理构造Query语句，慢SQL监控，分析慢日志，检查是否有大量的的子查询和关联查询、嵌套查询等，尽量避免使用这些查询， 使用连接（JOIN）来代替子查询(Sub-Queries)，使用联合(UNION)来代替手动创建的临时表。

##### 订单表

1. 主要通过订单id查询信息，可以按订单号/用户id/日期维度给拆分到多个库，在查询时携带库的条件，通过某个业务规则，直接定位到要查询的目标库。

2. 如果是CRM客户关系管理系统 ，不直接使用订单号直接查询，而是一个范围查询，返回一个列表集合。此时不适合用分库分表，因为需要对各库的查询结果集进行union，使得性能反而下降。

##### 缓存

1. mysql自带的query cache，对应用基本完全透明，但会受限于本机，而且只缓存查询结果，充分利用二级缓存减少数据库I/O操作。对数据库连接池，mybatis，hiberante二级缓存充分利用上。尽量使用顺序IO代替随机IO。
2. 可以用memcache做缓存，redis用于需要持久化的场景，memcache和redis可以缓存一些加工后的数据。
3. 缓存对于应用不是完全透明的，除非用Django这种成熟框架，而且缓存粒度很大。需要考虑如何保证缓存里的数据始终正确、写数据前还是后失效缓存、缓存挂了/写多读少导致缓存命中率低/数据过热导致流量压到后端mysql了怎么办、流量压倒后端mysql了怎么办、数据量大或QPS大时分片及HA的问题。

##### 复制/读写分离

1. 在应用层面或使用第三方工具（如360的atlas）做主从复制、主主复制、读写分离。实现备份、高可用、负载均衡。
2. 节点少的情况下，主备，主备几乎适用于大多数场景，甚至不论数据大小。前面加Keepalived+HAProxy等组件，失效自动切换。
3. 节点多的情况下，一是考虑多级备份，减轻主的压力。其次可以引入第三方组件，接管主节点的备份工作。主主不推荐，一是需要考虑数据冲突的情况，比如错开id，同时操作数据后的冲突解决。其次如果强一致会导致延迟增加，如果有节点挂了，需要等到超时才返回。
4. LVS+HAProxy做一下HA。

##### 切分

1. 包括垂直切分和水平切分，实现方式上又包括分库、分表。推荐。
2. 垂直切分保证业务的独立性，防止不同业务争抢资源，毕竟业务是有优先级的。垂直切分一般都要做，只不过业务粒度大小而已。根据业务垂直切分。业务内部分库、分表。一般都需要修改应用。除分表外，其余实现不是很复杂。有第三方组件可用，但通用高效又灵活的方式，还是自己写client。
3. 水平切分主要用于突破单机瓶颈。除了主主外，只有切分能真正做到将负载分配下去。切分后也可对不同片数据进行不同优化。如按时间切分，超过一定时间数据不允许修改，就可以引入压缩了，数据传输及读取减少很多。水平拆分有一定难度，但如果将来一定会到这个规模，又可能用到，建议越早做越好。因为对应用的改动较大，而且迁移成本高。
4. 分库有是经常用的，就算当前压力小，也尽量分出几个逻辑库出来。等规模上去了，很方便就迁移扩展。
5. MySQL 是关系数据库，数据库表之间的关系从一定的角度上映射了业务逻辑。任何分库分表的行为都会在某种程度上提升业务逻辑的复杂度，数据库除了承载数据的存储和访问外，协助业务更好的实现需求和逻辑也是其重要工作之一。分库分表会带来数据的合并，查询或者更新条件的分离，事务的分离等等多种后果，业务实现的复杂程度往往会翻倍或者指数级上升。所以，在分库分表之前，不要为分而分，去做其他力所能及的事情吧，例如升级硬件，升级网络，升级数据库版本，读写分离，负载均衡等等。

6. 对数据库的备份。如果单表或者单个实例太大，在做备份的时候需要大量的磁盘IO或者网络IO资源。例如1T的数据，网络传输占用50MB的时候，需要20000秒才能传输完毕，在此整个过程中的维护风险都是高于平时的。我们在Qunar的做法是给所有的数据库机器添加第二块网卡，用来做备份，或者SST，Group Communication等等各种内部的数据传输。1T的数据的备份，也会占用大量的磁盘IO，如果是SSD还好，当然这里忽略某些厂商的产品在集中IO的时候会出一些BUG的问题。如果是普通的物理磁盘，则在不限流的情况下去执行xtrabackup，该实例基本不可用。
7. 对数据表的修改。如果某个表过大，对此表做DDL的时候，MySQL会锁住全表，这个时间可能很长，在这段时间业务不能访问此表，影响甚大。解决的办法有类似腾讯游戏DBA自己改造的可以在线秒改表，不过他们目前也只是能添加字段而已，对别的DDL还是无效；或者使用pt-online-schema-change，当然在使用过程中，它需要建立触发器和影子表，同时也需要很长很长的时间，在此操作过程中的所有时间，都可以看做是风险时间。把数据表切分，总量减小，有助于改善这种风险。
8. 整个表热点，数据访问和更新频繁，经常有锁等待，你又没有能力去修改源码，降低锁的粒度，那么只会把其中的数据物理拆开，用空间换时间，变相降低访问压力。
9. 表设计不合理时，需要对某些字段垂直拆分。例如user表的last_login_time，用户很活跃导致表不断的被update，压力非常大。
10. 访问频率较低的大字段拆分出数据表。有些大字段占用空间多，访问频率较其他字段明显要少很多，这种情况进行拆分，频繁的查询中就不需要读取大字段，造成IO资源的浪费。如user表的personal_info基本不查询却是text占用很大空间。
11. 某些数据表出现了无穷增长时。各种的评论，消息，日志记录。这个时候增加存储、提升机器配置已经苍白无力了，水平切分是最佳实践。拆分的标准很多，按用户的，按时间的，按用途的。
12. 安全性和可用性的考虑。鸡蛋不要放在一个篮子里，不希望数据库出问题，但希望在出问题时影响到的用户比例越少越好。水平切分可以解决这个问题，把用户，库存，订单等等本来同统一的资源切分掉，每个小的数据库实例承担一小部分业务，这样整体的可用性就会提升。
13. 业务耦合性考虑。对于完全无关的业务，虽然每个业务的数据量可能不太大，放在一个MySQL实例中完全没问题，但开发水平不齐，导致一方业务搞挂了数据库，另一方业务也受影响。
