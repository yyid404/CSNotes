# MySQL

​		不区分大小写，默认字符检索策略为utf8_general_ci，区分大小写：utf8_general_cs、uft8_bin二进制比较。

## 组成架构

​		逻辑架构可分为服务层和存储引擎。服务层为MySQL的核心服务功能，查询语句解析、缓存、词法语句分析等。

### 连接器

​		负责管理连接，权限的验证等。

### 解析器

​		对输入的sql进行解析，进行词法分析，需要识别出里面的字符串代表什么意思。比如select代表查询，T代表某张表，ID代表某张表的列字段叫id。之后进行语法分析，根据语法规则，判断输入的sql语句是否符合mysql语法。

### 优化器

​		经过解析之后，mysql就知道你需要做什么事情了。但是在真正执行之前还需要经过优化器处理。比如当表中存在多个索引的时候，选择哪个索引来使用。或者多表关联的时候，选择各个表的连接先后顺序。

### 执行器

​		开始执行之前首先确认对该表有无执行查询的权限。如果没有，则返回错误的信息提示。如果有权限，则开始执行。

​		首先根据该表的引擎类型，使用这个引擎提供的接口。比如查询某表，然后利用某字段查找，如果没有添加索引，则调用引擎的接口取出第一行数据，判断结果是不是，如果不是，依次再调用引擎的下一行数据，直至取出这个表中所有的数据。如果该字段有索引，执行过程也大致相似。具体的数据是保存在引擎中的在Mysql中，常见的引擎有MyISAM和InnoDB。

## SQL执行过程

1. 客户端通过 TCP 连接发送连接请求到 mysql 连接器，连接器会对该请求进行权限验证及连接资源分配。
2. 建立连接后客户端发送一条语句，mysql 收到该语句后，通过命令分发器判断其是否是一条select 语句，如果是，在开启查询缓存的情况下，先在查询缓存中查找该 SQL 是否完全匹配，如果完全匹配，验证当前用户是否具备查询权限，如果权限验证通过，直接返回结果集给客户端，该查询也就完成了。如果不匹配继续向下执行。
3. 如果在查询缓存中未匹配成功，则将语句交给分析器作语法分析，MySQL 需要知道到底要查哪些东西，如果语法不对，就会返回语法错误中断查询。
4. 分析器的工作完成后，将语句传递给预处理器，检查数据表和数据列是否存在，解析别名看是否存在歧义等。
5. 语句解析完成后，MySQL 就知道要查什么了，之后会将语句传递给优化器进行优化（通过索引选择最快的查找方式），并生成执行计划。
6. 之后交给执行器去具体执行该语句，在执行之前，会先检查该用户是否具有查询权限，如果有，继续执行该语句。执行器开始执行后，会逐渐将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。

## 引擎

```
//建表时指定引擎：
create table 表名 ( … ) engine=MyISAM default charset=utf8;
```

### Innodb

​		支持外键，需有主键。如果我们定义了主键，那么InnoDB会选择主键作为聚集索引。

​		支持事务，每条SQL语句都将自动封装成事务，自动提交，影响速度。

​		支持表锁和行锁（默认），行锁由索引实现，若没有命中索引，则依然会使用表锁。但行锁和表锁的同时存在会发生冲突，如A申请了行共享锁，而B 再申请表互斥锁。这时 B 不仅需要查看是否已经存在其他表锁，以及逐个查看是否存在行锁，效率太低。于是又引入了意向锁。意向锁是一种表级锁，用来指示接下来的一个事务将要获取的是共享锁或者独占锁。

​		不保存表的行数，查询某张表的行数会进行全表扫描。

​		聚集索引，即数据文件和索引绑在一起，数据本身按索引形式来存储，为B+树结构。.frm 表结构文件、.ibd 数据文件。

​		适合写密集、高并发。

#### 主键

​		如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一列作为主键。如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引（ROWID随着行记录的写入而主键递增，这个ROWID不像ORACLE的ROWID那样可引用，是隐含的）。所以Innodb表最好要设置主键。

​		最好使用自增整数作为主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，即页面达到装载因子（InnoDB默认为15/16），就会自动开辟一个新的页。

​		如果采用UUID等非自增主键，那么插入的位置是不固定的，可能靠前，也可能靠后，后面再次插入进来，很有可能会导致原先的节点重新分裂。频繁的移动、分页操作增加开销，且造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。

### myisam

​		不支持外键，可以没有主键。

​		不支持事务

​		支持表锁

​		保存整个表的行数，执行速度很快。适合做很多count计算，但where筛选无效。

​		非聚集索引，即索引和数据文件分开存储。.frm 表结构文件、.MYD 数据文件、.MYI 索引文件。索引文件中存放对应数据的文件指针，接着会去MYD数据文件中去找对应指针的数据。

​		适合读密集。

## 索引

​		索引是可以帮助mysql高效获取数据的数据结构。未添加索引时，MySQL需从磁盘中遍历全表去查找某条记录。添加索引后，MySQL从索引文件中取出某条数据对应的磁盘地址，从磁盘中取出该条数据。

### 优缺点

​		数据索引的存储是有序的，在有序的情况下，通过索引查询一个数据是无需遍历索引记录的。极端情况下，数据索引的查询效率为二分法查询效率，趋近于 log2(N)。适当的使用索引可以提高数据检索速度，也可以降低数据库的IO成本，并且索引还可以降低数据库的排序成本。排序分组操作主要消耗的就是CPU资源和内存，所以能够在排序分组操作中好好的利用索引将会极大地降低CPU资源的消耗。可以给经常需要进行查询的字段创建索引。

​		创建索引和维护索引需要耗费时间，索引需要占用空间，进行数据的增删改时候需要动态维护索引。

### 实现原理

### 数据结构

#### 磁盘I/O

​		磁盘由盘片组成。盘片有两面，称之为盘面surface。盘面上覆盖磁性材料。中间是一个可以旋转的轴Spindle，使得整个盘面能够旋转。每个盘面又由一系列的同心圆组成，称之为磁道track。磁道又被划分为一组组扇区sector。扇区的大小大概都相等，为512字节。

​		当从磁盘中读取数据时，利用读写头找到对应的磁道，这个步骤称之为寻道。找到磁道后，盘片开始转动，磁道上的每个位都可以被磁头感知到，然后读取到其内容，

​		对磁盘的访问整个过程可以分为寻道时间和访问时间。一般情况下，寻道时间较慢。由于磁盘存取的速度比内存慢很多，所以磁盘读取时，通常情况下并不是按需读取，而是会预读一部分数据。预读的长度通常情况下为一个页的整数倍。一个页一般情况下大小为4k。也就是说一次磁盘IO通常只会读取4k的几倍。

​		索引本身很大，因此索引以索引表的形式存储在磁盘中，无法一次将全部索引加载到内存中，每次只能从磁盘中读取一个页到内存中。这样的话，索引查找过程中就要产生磁盘 I/O 消耗，相对于内存存取，I/O 存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘 I/O 操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘 I/O 的存取次数。

​		把全部数据写入到一个节点中，也并没有太大用处，因为一般只会读取4k或者4k的几倍。数据库的实现者也利用磁盘预读的这一点，将一个节点的大小设为4k或者4k的几倍。最好的状态是一次磁盘IO就把一个节点里全部数据给读取到内存中了。这样盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。

#### 二叉树

​		底层实现是数组，逻辑上相邻的节点在物理结构上可能相差很远。当数据量非常大时，树的深度非常深，树越深，硬盘和内存的交互次数将越多。硬盘和内存的交互速度慢，交互次数越多，则查询越慢。磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存，二叉树没能充分利用磁盘预读功能。

#### hash表

​		采用一定的哈希算法，把键值换算成新的哈希值，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。缺点：

- hash索引仅能查找=、in等查找，无法进行范围查找。
- 无法利用索引的数据来避免任何排序运算。
- 存在哈希碰撞问题。当数据量多的时候，不可避免的会出现很多数据重复堆叠在同一个下标，仍需遍历该下标下的所有元素。
- 不支持联合索引的最左前缀匹配规则。

​		常用的 InnoDB 引擎中默认使用的是B+树索引，它会实时监控表上索引的使用情况。如果认为建立哈希索引可以提高查询效率，则自动在内存中的“自适应哈希索引缓冲区”建立哈希索引（在InnoDB中默认开启自适应哈希索引）。通过观察搜索模式，MySQL会利用index key的前缀建立哈希索引，如果一个表几乎大部分都在缓冲池中，那么建立一个哈希索引能够加快等值查询。

​		在某些工作负载下，通过哈希索引查找带来的性能提升远大于额外的监控索引搜索情况和保持这个哈希表结构所带来的开销。但某些时候，在负载高的情况下，自适应哈希索引中添加的read/write锁也会带来竞争，比如高并发的join操作。like操作和%的通配符操作也不适用于自适应哈希索引，可能要关闭自适应哈希索引。

​		在HEAP表中，如果存储的数据重复度很低（也就是说基数很大），对该列数据以等值查询为主，没有范围查询、没有排序的时候，特别适合采用哈希索引，例如这种SQL：

```sql
//仅等值查询
select id, name from table where name='李明'; 
```

#### B-Tree

​		多路平衡查找树，m阶的B树，每个节点可以存储多个关键字。将节点大小设置为磁盘页的大小，充分利用了磁盘预读的功能。每次读取磁盘页时就会读取一整个节点，也正因每个节点存储着非常多个关键字，有效降低了树的高度，进而要执行的磁盘读取操作次数就会非常少，更多的是在内存中对读取进来的数据进行查找。

​		每个节点最多有m-1个key，至少2个key。每个节点最多m个孩子节点，n个key的节点有n+1个指针。非根节点包含的key个数满足：m/2向上取整-1<=j<=m-1。每个节点都是按照从小到大的顺序排列，所有叶子节点位于同一层。数据查询次数不稳定。

​		一次磁盘IO，即内存和磁盘间的数据交互，一次最多只会读写4k或4k的几倍。所以将节点的大小设置为4k左右，一次将一整个节点的数据读取进去。B树每个key都有对应的数据，增加了数据量的大小。每个key和data占用的空间越多，能存储的key的个数便越少。若节点大小相同的情况下，一个key和value占用了1k，则一个节点只能存4个key。引入B+树。

#### B+Tree

​		B+树是B树的变种，一个平衡的多叉树，从根节点到每个叶子节点的高度差值不超过1，而且同层级的节点间有指针相互链接，是有序的。非叶子节点不存储data，只存储key，便可以存储更多的key，即阶数会显著增加。把非叶子节点的key做适当的冗余，在最终的叶子节点内存储一份完整的key和对应的data。

​		每个父节点都会出现在子节点中，父节点是子节点中的最大或最小元素。所有叶子节点都有一个指针，指向下一个数据，形成链表。由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当，B+-tree的查询效率更加稳定，每次查询的次数都是树的高度。

​		通常，B+树索引结构适用于绝大多数场景。

​		B+树有主键索引和辅助索引。主键索引按照表中主键的顺序构建一颗 B+树，并在叶节点中存放表中的行记录数据，一个表只能有一个主键索引。辅助索引，叶节点并不存储行记录数据，仅仅是主键，通过辅助索引查找到对应的主键，最后在聚集索引中使用主键获取对应的行记录。

### 类型

#### 聚集索引

​		主键索引。每张表的主键构造一棵 B+树，叶子节点中存放整张表的行记录数据。该索引中键值的逻辑顺序即为表中相应行数据的物理存储顺序。一个表只能包含一个聚集索引。辅助索引的叶子节点存储数据的主键键值。

​		聚集索引对于那些经常要搜索范围值的列特别有效。使用聚集索引找到包含第一个值的行后，便可以确保包含后续索引值的行在物理相邻。例如，如果应用程序执行的一个查询经常检索某一日期范围内的记录，则使用聚集索引可以迅速找到包含开始日期的行，然后检索表中所有相邻的行，直到到达结束日期。这样有助于提高此类查询的性能。同样，如果对从表中检索的数据进行排序时经常要用到某一列，则可以将该表在该列上聚集（物理排序），避免每次查询该列时都进行排序，从而节省成本。

​		当索引值唯一时，使用聚集索引查找特定的行也很有效率。例如，使用唯一雇员 ID 列 emp_id 查找特定雇员的最快速的方法，是在 emp_id 列上创建聚集索引或 PRIMARY KEY 约束。

#### 非聚集索引

 		也叫辅助索引。主键B+树在叶子节点存储指向行数据的指针，即主键。目录与数据分开，索引顺序与数据物理存储顺序无关，通过辅助索引查找到对应的主键，最后在聚集索引中使用主键获取对应的行记录。主键索引和辅助索引一样。

#### 联合索引

​		建了一个(a,b,c)的复合索引，实际等于建了(a),(a,b),(a,b,c)三个索引。

##### 优缺点

- 利用覆盖索引，避免回表，直接通过遍历索引取得数据。减少了很多的随机io操作。减少io操作，特别是随机io其实是dba主要的优化策略。覆盖索引是主要的提升性能的优化手段之一。

    ```sql
    //索引id
    select id from user//不用回表，直接从索引中读取id的值。
    select id,name from user//不能返回除id列其他的值，需要回表。
    
    //联合索引(id,name)
    select id from user//避免回表，不用单独建立id列的单列索引。
    select id,name from user//避免回表
    ```

- 两个单列查询返回行较多，同时查返回行较少，使用联合索引更高效。索引列越多，通过索引筛选出的数据越少，效率更高。

- 多一个索引，都会增加写操作的开销和磁盘空间的开销，对于大量数据的表，这是不小的开销。

##### 最左前缀原则

​		联合索引指的是对多列创建了索引。比如对a，b，c创建了一个联合索引，其实相当于创建了a单列索引、（a，b）联合索引以及（a，b，c）联合索引。如果查询条件精确匹配联合索引的左边连续一列或者多列，则查询命中索引。一般把频率最高的列放在最左边。

```sql
//联合索引（a,b,c）
select a,b,c where b=?;
//where条件没有利用到索引，但abc均在索引树上，则仍会利用到索引。
```

### 建立

​		应当考虑表空间和磁盘空间是否足够。索引也是一种数据，在建立索引的时候势必也会占用大量表空间。因此在对一大表建立索引的时候首先应当考虑的是空间容量问题。

​		在对建立索引的时候要对表进行加锁，因此应当注意操作在业务空闲的时候进行。

#### 适合建索引

- 较频繁地作为查询条件在where或order by语句中出现的字段。单纯的 order by 不会用到索引，但如果在 where 中出现，就可以用索引了。
- 查询中与其他表关联的字段，外键关系建立索引。
- 用于聚合函数的列可以建立索引，例如max(column_1)或者 count(column_1)的 column_1。

#### 不适合建索引

- 表记录太少。
- 经常插入、删除、修改的表。
- 数据大量重复且分布平均的字段，假如一个表有10万行记录，比如性别可能就只有两个值，建索引不仅没什么优势，还会影响到更新速度，这被称为过度索引 。
- 经常和主字段一块查询但主字段索引值比较多的表字段。如电费实收表经常按收费序号、户标识编号、抄表日期、电费发生年月、操作 标志来具体查询某一笔收款的情况，如果将所有的字段都建在一个索引里那将会增加数据的修改、插入、删除时间，从实际上分析一笔收款如果按收费序号索引就已 经将记录减少到只有几条，如果再按后面的几个字段索引查询将对性能不产生太大的影响。
- 唯一性太差的字段不适合建立索引
- 更新太频繁地字段不适合创建索引
- 不会出现在where条件中的字段不该建立索引

### 优化

- 使用短索引（又叫前缀索引）来优化索引。
- 存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。范围列可以用到索引（联合索引必须是最左前缀），但是范围列后面的列无法用到索引，索引最多用于一个范围列，如果查询条件中有两个范围列则无法全用到索引。
- 利用覆盖索引来进行查询操作，避免回表。

#### 覆盖索引

​		如果一个索引包含（或者说覆盖）所有需要查询的字段的值，则称为覆盖索引。在 InnoDB 存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要回表，也就是要通过主键再查找一次，这样就会比较慢。覆盖索引就是把要查询出的列和索引是对应的，不做回表操作。InnoDB 存储引擎支持覆盖索引，即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。SQL 只需要通过索引就可以返回查询所需要的数据，而不必通过二级索引查到主键之后再去表里查询数据。

​		select 的数据列只用从索引中就能够取得，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖。

​		索引是高效找到行的一个方法，当能通过检索索引就可以读取想要的数据，那就不需要再到数据表中读取行了。如果一个索引包含了（或覆盖了）满足查询语句中字段与条件的数据就叫做覆盖索引。

​		是非聚集组合索引的一种形式，它包括在查询里的 Select、Join 和 Where 子句用到的所有列（即建立索引的字段正好是覆盖查询语句[select 子句]与查询条件[Where 子句]中所涉及的字段，也即，索引包含了查询正在查找的所有数据）。

### 失效

- 当对索引的列作出操作时。

    ```sql
    where left(name,1) = '张三'
    ```

- where子句使用!=或<>时

- 联合索引中有字段使用了范围查询时，语句中该字段后面的索引将失效。

    ```sql
    explain select * from student where age > 1 and name = '王五';
    //联合索引为(name,age)。age使用了范围，即使name是联合索引中的最左索引，也失效。
    ```

- is null 或 is not null

- like模糊查询时，以通配符开头会导致索引失效。可用ElasticSearch搜索引擎工具。

- 字符串不加单引号会导致类型转换，进而导致索引失效。

- like已 （解决方法：使用覆盖索引）

- 用or来连接索引会失效。

### 语法

查看某张表的索引：

```sql
show index from 表名；
```

创建普通索引：

```sql
alter table 表名 add index 索引名(索引列);
```

创建复合索引：

```sql
alter table 表名 add index 索引名(索引列1，索引列2);
```

删除某张表的索引：

```sql
drop index 索引名 on 表名;
```

### explain

​		explain你的select查询，可以模拟优化器执行sql语句，从而知道Mysql是如何处理sql的、索引主键被如何利用的，即可分析查询语句或是表结构的性能瓶颈。

**id**：select的编号，有几个select就有几个id值。id越大表示执行的优先级越高，越先执行；id相同则依次从上向下执行。在Mysql中select查询分为简单查询（SIMPLE）和复杂查询（PRIMARY）。复杂查询又分为：简单子查询、派生表（from语句的子查询）、union查询。

**table**：这一行explain正在访问的哪张表。当有 union 时，UNION RESULT 的 table 列的值为<union1,2>，1和2表示参与 union 的 select 行id。

**select_type**：每个select子句的类型

- SIMPLE：简单查询，未使用子查询和union等查询。
- PRIMARY：查询中如果包含子查询，那么最外层的查询叫做PRIMARY。也叫做主查询。查询的主体。
- SUBQUERY：select中的子查询
- UNION：union中的后面或者第二个select语句
- UNION RESULT：union的结果
- SUBQUERY：子查询中的第一个SELECT，结果不依赖于外部查询。
- DERIVED：派生表的 SELECT, FROM 子句的子查询。

**type**：表示关联类型或访问类型，即MySQL决定如何查找表中的行，查找数据行记录的大概范围。依次从最优到最差分别为： null > system > const > eq_ref > ref > range > index > ALL。一般来说，得保证查询达到range级别，最好达到ref。

- null：MySQL 在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。
- system：system 是 const 类型的特例，当查询的表只有一行的情况下，使用 system。
- const：当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量
- eq_ref：唯一性索引。返回的数据具有唯一性。主要用在联表查询中使用primary key或unique key作为关联条件的情况。
- ref：非唯一性索引，对于每个索引键的查询，返回匹配的所有行数据。即哪些列或常量被用于查找索引列上的值。
- range：检索指定范围的行，where条件后面是一个范围查询，比如，between、>、<等。
- index：遍历所有索引树。
- all：遍历全部的数据。

**possible_keys**：显示可能使用哪些索引来查找，不一定被使用。Explain出现possible_keys有列，而key显示null情况，因为表数据不多，mysql认为索引对此查询帮助不大，选择全表扫描。

**key**：显示mysql实际选择哪个索引来优化该表的访问。

**key_len**：显示mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。

**ref**：表示当前表在利用Key列记录中的索引进行查询时所用到的列或常量。

**rows**：表示mysql通过索引的统计信息，预算出来的所需要读取的行数，但是需要注意的是rows的值仅仅是统计学上的一个数据，并不是十分的准确。

**xtra:** 含 MySQL 解决查询的详细信息，有以下几种情况：

- Using where：不用读取表中所有信息，仅通过索引就可以获取所需数据，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示 mysql 服务器将在存储引擎检索行后再进行过滤。
- Using temporary：表示 MySQL 需要使用临时表来存储结果集，常见于排序和分组查询，常见 group by ; order by。
- Using filesort：当 Query 中包含 order by 操作，而且无法利用索引完成的排序操作称为“文件排序。
- Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。
- Impossible where：这个值强调了 where 语句会导致没有符合条件的行（通过收集统计信息不可能存在结果）。
- Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行，
- No tables used：Query 语句中使用 from dual 或不含任何 from 子句。

## 锁机制

三种并发控制机制：

- 悲观并发控制：锁
- 乐观并发控制：乐观锁.
- 多版本并发控制：MVCC多版本并发控制机制，可以与前两者中的任意一种机制结合使用，以提高数据库的读性能。

### 乐观锁

​		 总是认为不会产生并发问题，每次去取数据的时候总认为不会有其他线程对数据进行修改，因此不会上锁，先访问数据，在更新时再判断其他线程在这之前有没有对数据进行修改。数据库不自带，一般会使用版本号机制或CAS操作实现。

#### 实现

##### 版本号实现

​		一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。

> 例如：
>
> 1. 在需要的记录表中加上version字段，每做一次update都要让version+1，所以在修改某一条记录前先读取该条记录的version记为v，在执行update时加上where version = v，如果期间有其他的线程修改了这条记录，必然导致where条件不成立，这样重复这一操作知道成功执行修改操作。
> 2. 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。当需要对账户信息表进行更新的时候，需要首先读取version字段。操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。
> 3. 操作员 A 完成了修改工作，提交更新之前会先看数据库的版本和自己读取到的版本是否一致，一致的话，就会将数据版本号加1（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。
> 4. 操作员 B 完成了操作，提交更新之前会先看数据库的版本和自己读取到的版本是否一致，但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，而自己读取到的版本号为1 ，不满足 “ 当前最后更新的version与操作员第一次读取的版本号相等 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。
> 5. 这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。

##### CAS算法实现

​		即compare and swap 或者 compare and set，是一种无锁算法，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数，需要读写的内存值，预期值，新值。当需要更新时，判断当前内存值与之前取到的值是否相等，若相等，则用新值更新，若失败则不会执行任何操作（比较和替换是一个原子操作），一般情况下是一个自旋操作，即不断的重试。

### 悲观锁

​		总是假设最坏的情况，每次取数据时都认为其他线程会修改，所以都会加锁（读锁、写锁、行锁等），当其他线程想要访问数据时，都需要阻塞挂起。可以依靠数据库实现，如行锁、读锁和写锁等，都是在操作之前加锁，在Java中，synchronized的思想也是悲观锁。按照锁的粒度分为表级锁和行级锁。

#### 行锁

​		只针对当前操作的行进行加锁。

优点：

- 当在许多线程中访问不同的行时只存在少量锁定冲突。
- 回滚时只有少量的更改
- 可以长时间锁定单一的行。
- 加锁粒度最小，并发度高。

 缺点：

- 比页级或表级锁定占用更多的内存。
- 当在表的大部分中使用时，比页级或表级锁定速度慢，因为你必须获取更多的锁。加锁的开销也最大，加锁慢，会出现死锁。
- 如果你在大部分数据上经常进行GROUP BY操作或者必须经常扫描整个表，比其它锁定明显慢很多。

#### 表锁

​		对当前操作的整张表加锁,实现简单，加锁快，不死锁，但并发能力低。

#### Next-Key Lock

​		MySQL InnoDB 默认支持可重复读，使用了 Next-Key Lock 算法避免了幻读的发生。锁定索引项本身和索引范围。NK 是一种记录锁和间隙锁的组合锁。既锁住行，也锁住间隙。即 Record Lock 和 Gap Lock 的结合。可解决幻读问题。

#### Record Lock 记录锁

​		锁住某一行，如果表存在索引，那么记录锁是锁在索引上的，如果表没有索引，那么 InnoDB 会创建一个隐藏的聚簇索引加锁。

#### Gap LocK 间隙锁

​		间隙锁是一种记录行与记录行之间存在空隙或在第一行记录之前或最后一行记录之后产生的锁。间隙锁可能占据的单行，多行或者是空记录。 对索引项之间的“间隙”加锁，锁定记录的范围,不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。

#### 读锁

​		Share Locks，又被称为共享锁，其他用户可以并发读取数据，但任何事务都不能获取数据上的排他锁，直到已释放所有共享锁。

#### 写锁

​		Exclusive lock，排它锁，也叫X锁。若事务 T 对数据对象 A 加上 X 锁，则只允许 T 读取和修改 A，其它任何事务都不能再对 A 加任何类型的锁，直到 T 释放 A 上的锁。

#### 意向锁

​		表级锁。在意向锁存在的情况下，事务 A 必须先申请表的意向共享锁，成功后再申请一行的行锁。而事务 B发现表上有意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务 B 申请表的写锁会被阻塞。而且，申请意向锁的动作是数据库自动完成的，不需要我们手动申请。

##### 意向共享锁

​		IS。事务打算给数据行加共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS 锁。

##### 意向排他锁

​		IX。事务打算给数据行加排他锁，事务在给一个数据行加排他锁前必须先取得该表的

### MVCC

​		Multiversion Concurrency Control，多版本控制。指的是一种提高并发的技术。最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了 InnoDB 的并发度。
​		每一个写操作都会创建一个新版本的数据，读操作会从有限多个版本的数据中挑选一个最合适的结果直接返回。在这时，读写操作之间的冲突就不再需要被关注，而管理和快速挑选数据的版本就成了 MVCC 需要解决的主要问题。
​		各数据库中 MVCC 实现并不统一，MVCC 只在 READ COMMITTED 和 REPEATABLE READ两个隔离级别下工作。对于使用 InnoDB 存储引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列：trx_id事务ID、roll_pointer上个版本指针，其实还有一个 row_id 的隐藏列但这里用不着。每次对记录进行改动，都会把对应的事务id 赋值给 trx_id 隐藏列，也会把旧的版本写入到 undo 日志中。

​		所以在并发情况下，一个记录可能存在多个版本，通过 roll_pointer 形成一个版本链。MVCC 的核心任务就是：判断一下版本链中的哪个版本是当前事务可见的。这就有了 ReadView 的概念，这个ReadView 中主要包含当前系统中还有哪些活跃的读写事务，把它们的事务 id 放到一个列表中，我们把这个列表命名为为 m_ids；根据 ReadView 的活跃事务 ID 列表和版本链事务 ID 进行比较找出可见的事务 ID 最大的版本：

- 如果版本的 trx_id 属性值小于 m_ids 列表中最小的事务 id，表明生成该版本的事务在生成
    ReadView 前已经提交，所以该版本可以被当前事务访问。
- 如果版本的 trx_id 属性值大于 m_ids 列表中最大的事务 id，表明生成该版本的事务在生成
    ReadView 后才生成，所以该版本不可以被当前事务访问。
- 被访问版本的 trx_id 属性值在 m_ids 列表中最大的事务 id 和最小事务 id 之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。

​        多版本并发控制指的就是在使用 READ COMMITTD、REPEATABLE READ 这两种隔离级别的事务在执行普通的 SEELCT 操作时访问记录的版本链的过程，这样子可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。READ COMMITTD、REPEATABLE READ 这两个隔离级别的一个很大不同就是生成 ReadView 的时机不同，READ COMMITTD 在每一次进行普通 SELECT操作前都会生成一个 ReadView，而 REPEATABLE READ 只在第一次进行普通 SELECT 操作前生成一个 ReadView，之后的查询操作都重复这个 ReadView 就好了。

### 死锁

#### 处理方式

- 等待，直到超时，事务自动回滚。
- 发起死锁检测， 回滚一个事务，让其他事务执行。

#### 检测

​		构建一个以事务为起点，锁为边的有向图，看是否存在环。

## 连接池

​		池化设计会初始预设资源，解决的问题就是抵消每次获取资源的消耗，如创建线程的开销，获取远程连接的开销等。除了初始化资源，池化设计还包括如下这些特征：池子的初始值、池子的活跃值、池子的最大值等，这些特征可以直接映射到java线程池和数据库连接池的成员属性中。

​		数据库连接本质就是一个 socket 的连接。数据库服务端还要维护一些缓存和用户权限信息之类的所以占用了一些内存。我们可以把数据库连接池是看做是维护的数据库连接的缓存，以便将来需要对数据库的请求时可以重用这些连接。为每个用户打开和维护数据库连接，尤其是对动态数据库驱动的网站应用程序的请求，既昂贵又浪费资源。在连接池中，创建连接后，将其放置在池中，并再次使用它，因此不必建立新的连接。如果使用了所有连接，则会建立一个新连接并将其添加到池中。 连接池还减少了用户必须等待建立与数据库的连接的时间。

## 复制/同步

### 主从复制

​		MySQL主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。MySQL自带主从复制功能。

#### 原理

​		MySQL主从复制的基础是主服务器对数据库修改记录二进制日志，把主库的二进制日志文件 binlog复制到从库上，然后从库在本地完全顺序的执行日志中的各种操作。

#### 过程

1. 主节点 log dump 线程：当从节点连接主节点时，主节点会创建一个 log dump 线程，用于发送 bin-log 的内容。在读取 bin-log 中的操作时，此线程会对主节点上的 bin-log 加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。
2. 从节点I/O线程：当从节点上执行`start slave`命令之后，从节点会创建一个 I/O 线程用来连接主节点，请求主库中更新的 bin-log。I/O线程根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点，返回信息中除了日志所包含的信息之外，还包括本次返回的信息的bin-log position。接收到主节点 bin log dump 进程发来的更新之后，保存在本地 relay-log 中。并将读取到的 binary log 文件名和位置保存到 master-info 文件中。
3. 从节点 SQL 线程：SQL 线程负责读取 relay log 中的内容，检测到新增了内容后，解析成具体的操作并执行，最终保证主从数据的一致性。

#### 复制模式

##### 异步复制

​		默认采用异步复制方式，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，主节点不会主动 push bin log 到从节点。这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。

##### 半同步模式 

​		mysql semi-sync。这种模式下主节点只需要接收到其中一台从节点的返回信息，就会commit；否则需要等待直到超时时间然后切换成异步模式再提交；这样做的目的可以使主从数据库的数据延迟缩小，可以提高数据安全性，确保了事务提交后，binlog至少传输到了一个从节点上，不能保证从节点将此事务更新到db中。性能上会有一定的降低，响应时间会变长。半同步模式不是 mysql 内置的，需要装插件开启半同步模式。

##### 全同步模式

​		全同步模式是指主节点和从节点全部执行了 commit 并确认才会向客户端返回成功。	

#### 作用

- 读写分离，提高性能和并发能力。随着系统中业务访问量的增大，如果是单机部署数据库，就会导致I/O访问频率过高。有了主从复制，增加多个数据存储节点，将负载分布在多个从节点上，降低单机磁盘I/O访问的频率，提高单个机器的I/O性能。
- 及实时备灾，用于故障切换。一般会让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作；从库可以实时从主库进行复制，这样就可以做数据的热备。

#### 问题

- 主库宕机后数据可能会丢失。采用半同步复制解决数据丢失问题。
- 主库写压力大时，复制可能会有延迟。采用并行复制解决从库复制延迟的问题。
- 读写分离造成的过期读问题。解决方案为对查询请求进行分类，对于必须要拿到最新结果的请求，强制将其发送给主库。或者主库更新后，从库读之前先sleep一下，类似于执行一条`select sleep(1)`命令。

#### binlog记录格式

- 基于 SQL 语句的复制：记录会修改数据的 sql 语句到 binlog 中，减少了 binlog日志量，节约 IO，提高性能。某些情况会导致主从节点中数据不一致。
- 基于行的复制：将 SQL 语句分解为基于 Row 更改的语句并记录在 bin log 中，也就是只记录哪条数据被修改了，修改成什么样。优点是解决了特定情况下的存储过程、或者函数、或者 trigger 的调用或者触发无法被正确复制的问题。缺点是日志量太大。
- 混合方式：能语句就语句，不能语句就切换行

## 拆分

​		MySQL单表性能瓶颈在500w左右，具体与表结构设计和机器配置有关。

> 《阿里巴巴开发手册》中提出：单表行数超过500w或单表容量超过2G，推荐使用分库分表。

### 分库

​		使用mycat或sharing-JDBC等中间件作为数据库的代理。

### 分表

​		单表业务量过大，可采用按业务分表或按时间分表等手段将一张表分解成多张不同的表。分区从逻辑上来讲只有一张表，而分表则是将一张表分解成多张表。

### 表分区

​		表分区，是指根据一定规则，将数据库中的一张表分解成多个更小的，容易管理的部分。从逻辑上看，只有一张表，但是底层却是由多个物理分区组成。

​		输入命令：`show variables like '%partition%'` ，若have_partintioning 的值为YES，则表示当前MySQL支持分区。

#### 类型

**RANGE分区**：这种模式允许将数据划分不同范围。例如可以将一个表通过年份划分成若干个分区。

**LIST区**：这种模式允许系统通过预定义的列表的值来对数据进行分割。按照List中的值分区，与RANGE的区别是，range分区的区间范围值是连续的。

**HASH分区**：这中模式允许通过对表的一个或多个列的Hash Key进行计算，最后通过这个Hash码不同数值对应的数据区域进行分区。例如可以建立一个对表主键进行分区的表。

**KEY分区**：上面Hash模式的一种延伸，这里的Hash Key是MySQL系统产生的。

#### 好处

- 存储更多数据。分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备。和单个磁盘或者文件系统相比，可以存储更多数据。

- 优化查询。在where语句中包含分区条件时，可以只扫描一个或多个分区表来提高查询效率；涉及sum和count语句时，也可以在多个分区上并行处理，最后汇总结果。
- 易维护。例如：想批量删除大量数据可以清除整个分区。
- 避免某些特殊的瓶颈。例如InnoDB的单个索引的互斥访问，ext3问价你系统的inode锁竞争等。

#### 限制

- 一个表最多只能有1024个分区。
- MySQL5.1中，分区表达式必须是整数，或者返回整数的表达式。在MySQL5.5中提供了非整数表达式分区的支持。
- 如果分区字段中有主键或者唯一索引的列，那么多有主键列和唯一索引列都必须包含进来。即：分区字段要么不包含主键或者索引列，要么包含全部主键和索引列。
- 分区表中无法使用外键约束
- MySQL的分区适用于一个表的所有数据和索引，不能只对表数据分区而不对索引分区，也不能只对索引分区而不对表分区，也不能只对表的一部分数据分区。

### 分布式ID

​		ID是数据的唯一标识，传统的做法是利用UUID和数据库的自增ID，在互联网企业中，大部分公司使用的都是Mysql，并且因为需要事务支持，所以通常会使用Innodb存储引擎，UUID太长以及无序，所以并不适合在Innodb中来作为主键，自增ID比较合适，但是随着公司的业务发展，数据量将越来越大，需要对数据进行分表，而分表后，每个表中的数据都会按自己的节奏进行自增，很有可能出现ID冲突。这时就需要一个单独的机制来负责生成唯一ID，生成出来的ID也可以叫做分布式ID，或全局ID。下面来分析各个生成分布式ID的机制。常用的分布式ID方案有：

- 雪花算法
- UUID
- 数据库自增ID
- 数据库多主模式
- 号段模式
- Redis
- 滴滴Tinyid
- 百度Uidgenerator
- 美团Leaf

#### UUID

​		不适合作为主键，因为太长了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标示比如文件的名字。

#### 数据库自增ID

​		两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。这种方式生成的 id 有序，但是需要独立部署数据库实例，成本高，还会有性能瓶颈。

>这种生成分布式ID的机制，需要使用一个单独的Mysql实例。
>
>新建一个单独的表，表结构如下：
>
>```sql
>CREATE DATABASE `SEQID`;
>
>CREATE TABLE SEQID.SEQUENCE_ID (
>	id bigint(20) unsigned NOT NULL auto_increment, 
>	stub char(10) NOT NULL default '',
>	PRIMARY KEY (id),
>	UNIQUE KEY stub (stub)
>) ENGINE=MyISAM;
>```
>
>可以使用下面的语句生成并获取到一个自增ID
>
>```sql
>begin;
>replace into SEQUENCE_ID (stub) VALUES ('anyword');
>select last_insert_id();
>commit;
>```
>
>stub字段在这里并没有什么特殊的意义，只是为了方便的去插入数据，只有能插入数据才能产生自增id。而对于插入我们用的是replace，replace会先看是否存在stub指定值一样的数据，如果存在则先delete再insert，如果不存在则直接insert。

​		这种方法虽然可行，但是基于性能与可靠性来考虑的话都不够，业务系统每次需要一个ID时，都需要请求数据库获取，性能低，并且如果此数据库实例下线了，那么将影响所有的业务系统。为了解决数据可靠性问题，可以采用数据库多主模式。

#### 数据库多主模式

​		如果我们两个数据库组成一个主从模式集群，正常情况下可以解决数据库可靠性问题，但是如果主库挂掉后，数据没有及时同步到从库，这个时候会出现ID重复的现象。我们可以使用双主模式集群，也就是两个Mysql实例都能单独的生产自增ID，这样能够提高效率，但是如果不经过其他改造的话，这两个Mysql实例很可能会生成同样的ID。需要单独给每个Mysql实例配置不同的起始值和自增步长。

>第一台Mysql实例配置：
>
>```sql
>set @@auto_increment_offset = 1;     -- 起始值
>set @@auto_increment_increment = 2;  -- 步长
>```
>
>第二台Mysql实例配置：
>
>```sql
>set @@auto_increment_offset = 2;     -- 起始值
>set @@auto_increment_increment = 2;  -- 步长
>```
>
>经过上面的配置后，这两个Mysql实例生成的id序列如下： mysql1,起始值为1,步长为2,ID生成的序列为：1,3,5,7,9,... mysql2,起始值为2,步长为2,ID生成的序列为：2,4,6,8,10,...

​		对于这种生成分布式ID的方案，需要单独新增一个生成分布式ID应用，比如DistributIdService，该应用提供一个接口供业务应用获取ID，业务应用需要一个ID时，通过rpc的方式请求DistributIdService，DistributIdService随机去上面的两个Mysql实例中去获取ID。

​		实行这种方案后，就算其中某一台Mysql实例下线了，也不会影响DistributIdService，DistributIdService仍然可以利用另外一台Mysql来生成ID。

​		但是这种方案的扩展性不太好，如果两台Mysql实例不够用，需要新增Mysql实例来提高性能时，这时就会比较麻烦。

​		现在如果要新增一个实例mysql3，要怎么操作呢？ 第一，mysql1、mysql2的步长肯定都要修改为3，而且只能是人工去修改，这是需要时间的。 第二，因为mysql1和mysql2是不停在自增的，对于mysql3的起始值我们可能要定得大一点，以给充分的时间去修改mysql1，mysql2的步长。 第三，在修改步长的时候很可能会出现重复ID，要解决这个问题，可能需要停机才行。

​		为了解决上面的问题，以及能够进一步提高DistributIdService的性能，可以采用号段模式。

#### 号段模式

​		我们可以使用号段的方式来获取自增ID，号段可以理解成批量获取，比如DistributIdService从数据库获取ID时，如果能批量获取多个ID并缓存在本地的话，那样将大大提供业务应用获取ID的效率。

>例如： DistributIdService每次从数据库获取ID时，就获取一个号段，比如(1,1000]，这个范围表示了1000个ID，业务应用在请求DistributIdService提供ID时，DistributIdService只需要在本地从1开始自增并返回即可，而不需要每次都请求数据库，一直到本地自增到1000时，也就是当前号段已经被用完时，才去数据库重新获取下一号段。
>
>所以，我们需要对数据库表进行改动，如下：
>
>```sql
>CREATE TABLE id_generator (
>id int(10) NOT NULL,
>current_max_id bigint(20) NOT NULL COMMENT '当前最大id',
>increment_step int(10) NOT NULL COMMENT '号段的长度',
>PRIMARY KEY (`id`)
>) ENGINE=InnoDB DEFAULT CHARSET=utf8;
>```
>
>这个数据库表用来记录自增步长以及当前自增ID的最大值（也就是当前已经被申请的号段的最后一个值），因为自增逻辑被移到DistributIdService中去了，所以数据库不需要这部分逻辑了。
>
>这种方案不再强依赖数据库，就算数据库不可用，那么DistributIdService也能继续支撑一段时间。但是如果DistributIdService重启，会丢失一段ID，导致ID空洞。
>
>为了提高DistributIdService的高可用，需要做一个集群，业务在请求DistributIdService集群获取ID时，会随机的选择某一个DistributIdService节点进行获取，对每一个DistributIdService节点来说，数据库连接的是同一个数据库，那么可能会产生多个DistributIdService节点同时请求数据库获取号段，那么这个时候需要利用乐观锁来进行控制，比如在数据库表中增加一个version字段，在获取号段时使用如下SQL：
>
>```sql
>update id_generator set current_max_id=#{newMaxId}, version=version+1 where version = #{version}
>```
>
>因为newMaxId是DistributIdService中根据oldMaxId+步长算出来的，只要上面的update更新成功了就表示号段获取成功了。
>
>为了提供数据库层的高可用，需要对数据库使用多主模式进行部署，对于每个数据库来说要保证生成的号段不重复，这就需要利用最开始的思路，再在刚刚的数据库表中增加起始值和步长，比如如果现在是两台Mysql，那么 mysql1将生成号段（1,1001]，自增的时候序列为1，3，4，5，7.... mysql1将生成号段（2,1002]，自增的时候序列为2，4，6，8，10...

​		更详细的可以参考滴滴开源的TinyId，在TinyId中还增加了一步来提高效率，在上面的实现中，ID自增的逻辑是在DistributIdService中实现的，而实际上可以把自增的逻辑转移到业务应用本地，这样对于业务应用来说只需要获取号段，每次自增时不再需要请求调用DistributIdService了。

#### 雪花算法

​		数据库自增ID、数据库多主模式、号段模式这三种方法总的来说是基于自增思想。我们可以换个角度来对分布式ID进行思考，只要能让负责生成分布式ID的每台机器在每毫秒内生成不一样的ID就行了。

​		snowflake是twitter开源的分布式ID生成算法，是一种算法，它不依赖数据库。核心思想是：分布式ID固定是一个long型的数字，一个long型占8个字节，也就是64个bit，原始snowflake算法中对于bit的分配如下图：

![雪花算法](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/雪花算法.png)

​		第一个bit位是标识部分，在java中由于long的最高位是符号位，正数是0，负数是1，一般生成的ID为正数，所以固定为0。

​		时间戳部分占41bit，这个是毫秒级的时间，一般实现上不会存储当前的时间戳，而是时间戳的差值（当前时间-固定的开始时间），这样可以使产生的ID从更小值开始；41位的时间戳可以使用69年，(1L << 41) / (1000L * 60 * 60 * 24 * 365) = 69年。

​		工作机器id占10bit，这里比较灵活，比如，可以使用前5位作为数据中心机房标识，后5位作为单机房机器标识，可以部署1024个节点。

​		序列号部分占12bit，支持同一毫秒内同一个节点可以生成4096个ID

​		根据这个算法的逻辑，只需要将这个算法用Java语言实现出来，封装为一个工具方法，那么各个业务应用可以直接使用该工具方法来获取分布式ID，只需保证每个业务应用有自己的工作机器id即可，而不需要单独去搭建一个获取分布式ID的应用。

​		在大厂里，其实并没有直接使用snowflake，而是进行了改造，因为snowflake算法中最难实践的就是工作机器id，原始的snowflake算法需要人工去为每台机器去指定一个机器id，并配置在某个地方从而让snowflake从此处获取机器id。但是在大厂里，机器是很多的，人力成本太大且容易出错，所以大厂对snowflake进行了改造。

​		snowflake算法实现起来并不难，提供一个github上用java实现的：https://github.com/beyondfengyu/SnowFlake

#### 百度uid-generator

​		uid-generator使用的就是snowflake，只是在生产机器id，也叫做workId时有所不同。

​		uid-generator中的workId是由uid-generator自动生成的，并且考虑到了应用部署在docker上的情况，在uid-generator中用户可以自己去定义workId的生成策略，默认提供的策略是：应用启动时由数据库分配。说的简单一点就是：应用在启动时会往数据库表(uid-generator需要新增一个WORKER_NODE表)中去插入一条数据，数据插入成功后返回的该数据对应的自增唯一id就是该机器的workId，而数据由host，port组成。

​		对于uid-generator中的workId，占用了22个bit位，时间占用了28个bit位，序列化占用了13个bit位，需要注意的是，和原始的snowflake不太一样，时间的单位是秒，而不是毫秒，workId也不一样，同一个应用每重启一次就会消费一个workId。

​		github地址：https://github.com/baidu/uid-generator

#### 美团Leaf

​		美团的Leaf也是一个分布式ID生成框架。它非常全面，即支持号段模式，也支持snowflake模式。能保证全局唯一性、趋势递增、单调递增、信息安全，但也需要依赖关系数据库、Zookeeper等中间件。

​		Leaf中的snowflake模式和原始snowflake算法的不同点，也主要在workId的生成，Leaf中workId是基于ZooKeeper的顺序Id来生成的，每个应用在使用Leaf-snowflake时，在启动时都会都在Zookeeper中生成一个顺序Id，相当于一台机器对应一个顺序节点，也就是一个workId。

​		github地址：https://github.com/Meituan-Dianping/Leaf

#### Redis

​		使用Redis来生成分布式ID，其实和利用Mysql自增ID类似，可以利用Redis中的incr命令来实现原子性的自增与返回。

​		性能比较好，灵活方便，不依赖于数据库。但是，引入了新的组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本。

> 例如：
>
> ```
> 127.0.0.1:6379> set seq_id 1     // 初始化自增ID为1
> OK
> 127.0.0.1:6379> incr seq_id      // 增加1，并返回
> (integer) 2
> 127.0.0.1:6379> incr seq_id      // 增加1，并返回
> (integer) 3
> ```

​		使用redis的效率是非常高的，但是要考虑持久化的问题。Redis支持RDB和AOF两种持久化的方式。

​		RDB持久化相当于定时打一个快照进行持久化，如果打完快照后，连续自增了几次，还没来得及做下一次快照持久化，这个时候Redis挂掉了，重启Redis后会出现ID重复。

​		AOF持久化相当于对每条写命令进行持久化，如果Redis挂掉了，不会出现ID重复的现象，但是会由于incr命令过得，导致重启恢复数据时间过长。

## 优化

### 查询缓慢原因

- 没有索引或者没有用到索引(这是查询慢最常见的问题，是程序设计的缺陷)
- I/O吞吐量小，形成了瓶颈效应。
- 没有创建计算列导致查询不优化。
- 内存不足，网络速度慢。
- 查询出的数据量过大（可以采用多次查询，其他的方法降低数据量）
- 锁或者死锁(这也是查询慢最常见的问题，是程序设计的缺陷)
- 返回了不必要的行和列
- 查询语句不好，没有优化。

### 查询优化

- 升级硬件
- 把数据、日志、索引放到不同的I/O设备上，增加读取速度。
- 纵向、横向分割表，减少表的尺寸。
- 选择正确的存储引擎
- DB Server 和APPLication Server 分离
- 开启查询缓存，优化查询。
- Prepared Statements，一种运行在后台的SQL语句集合，可以检查一些绑定好的变量，这样可以保护程序不会受到“SQL注入式”攻击。
- 对查询进行优化，为频繁搜索的字段建索引，尽量避免全表扫描。
- 根据查询条件，优化SQL语句。

### 千万级大表优化

​		当MySQL单表记录数过大时，数据库的CRUD性能会明显下降。任何优化，首先都需要了解你的业务和数据。QPS要到多少、带宽及存储是否足够、读写比例、HA需要做到什么程度，不同场景有不同的侧重。

#### 表设计

​		设计阶段就需要预计QPS及数据规模，参考业务场景对数据的要求，合理设计表结构，甚至违反设计范式做到适当冗余，合理建索引。

##### 数据库字段/类型定义

- 经常需要计算和排序等消耗CPU的字段,应该尽量选择更为迅速的字段，如用TIMESTAMP（4个字节）代替Datetime（8个字节），通过整型替代浮点型和字符型。

- 变长字段使用varchar，不要使用char。

- 对于二进制多媒体数据，流水队列数据(如日志)，超大文本数据不要放在数据库字段中。

- 业务逻辑执行过程必须读到的表中必须要有初始的值，避免业务读出为负或无穷大的值导致程序失败。

- 并不需要一定遵守范式理论，适度的冗余，让Query尽量减少Join。

- 关于时间的类型：

    <img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/总结-常用日期存储方式.jpg" style="zoom:50%;" />

    > 《高性能MySQL》中的推荐：
    >
    > 除了特殊行为之外，通常也应该尽量使用TIMESTAMP，因为它比DATETIME空间效率更高。有时候人们会将Unix时间截存储为整数值，但这不会带来任何效益。用整数保存时间截的格式通常不方便处理，所以我们不推荐这么做。
    > 不要用字符串存储日期：

    - 字符串占用的空间更大。
    - 字符串存储的日期比较效率比较低（逐个字符进行比对），无法用日期相关的 API 进行计算和比较。

    Datetime 和 Timestamp 之间抉择：

    - DateTime 类型是没有时区信息的（时区无关） ，DateTime 类型保存的时间都是当前会话所设置的时区对应的时间。这样就会有什么问题呢？当你的时区更换之后，比如你的服务器更换地址或者更换客户端连接时区设置的话，就会导致你从数据库中读出的时间错误。不要小看这个问题，很多系统就是因为这个问题闹出了很多笑话。

    - Timestamp 和时区有关。Timestamp 类型字段的值会随着服务器时区的变化而变化，自动换算成相应的时间，说简单点就是在不同时区，查询到同一个条记录此字段的值会不一样。

        一些关于 MySQL 时区设置的一个常用 sql 命令：

        ```sql
        # 查看当前会话时区
        SELECT @@session.time_zone;
        # 设置当前会话时区
        SET time_zone = 'Europe/Helsinki';
        SET time_zone = "+00:00";
        # 数据库全局时区设置
        SELECT @@global.time_zone;
        # 设置全局时区
        SET GLOBAL time_zone = '+8:00';
        SET GLOBAL time_zone = 'Europe/Helsinki';
        ```

    - DateTime 类型耗费空间更大。Timestamp 只需要使用 4 个字节的存储空间，但是 DateTime 需要耗费 8 个字节的存储空间。但是，这样同样造成了一个问题，Timestamp 表示的时间范围更小。Timestamp 在不同版本的 MySQL 中有细微差别。

        ```
        DateTime ：1000-01-01 00:00:00 ~ 9999-12-31 23:59:59
        Timestamp： 1970-01-01 00:00:01 ~ 2037-12-31 23:59:59
        ```

    MySQL 日期类型存储空间：

    - 5.6.4 之后的 MySQL 多出了一个需要 0 ～ 3 字节的小数位。Datatime 和 Timestamp 会有几种不同的存储空间占用。为了方便，本文我们还是默认 Timestamp 只需要使用 4 个字节的存储空间，但是 DateTime 需要耗费 8 个字节的存储空间。

    数值型时间戳：

    - 很多时候，我们也会使用 int 或者 bigint 类型的数值也就是时间戳来表示时间。这种存储方式的具有 Timestamp 类型的所具有一些优点，并且使用它的进行日期排序以及对比等操作的效率会更高，跨系统也很方便，毕竟只是存放的数值。缺点也很明显，就是数据的可读性太差了，你无法直观的看到具体时间。
    - 时间戳的定义如下：时间戳的定义是从一个基准时间开始算起，这个基准时间是「1970-1-1 00:00:00 +0:00」，从这个时间开始，用整数表示，以秒计时，随着时间的流逝这个时间整数不断增加。这样一来，我只需要一个数值，就可以完美地表示时间了，而且这个数值是一个绝对数值，即无论的身处地球的任何角落，这个表示时间的时间戳，都是一样的，生成的数值都是一样的，并且没有时区的概念，所以在系统的中时间的传输中，都不需要进行额外的转换了，只有在显示给用户的时候，才转换为字符串格式的本地时间。


##### 索引

- 合理使用索引，避免全表扫描。
- 业务需要的相关索引是根据实际的设计所构造sql语句的where条件来确定的，业务不需要的不要建索引，不允许在联合索引（或主键）中存在多余的字段。
- 唯一确定一条记录的一个字段或多个字段要建立主键或者唯一索引，不能唯一确定一条记录，为了提高查询效率建普通索引。
- 业务使用的表，有些记录数很少，甚至只有一条记录，为了约束的需要，也要建立索引或者设置主键。
- 对于取值不能重复，经常作为查询条件的字段，应该建唯一索引(主键默认唯一索引)，并且将查询条件中该字段的条件置于第一个位置。没有必要再建立与该字段有关的联合索引。
- 对于经常查询的字段，其值不唯一，也应该考虑建立普通索引，查询语句中该字段条件置于第一个位置，对联合索引处理的方法同样。
- 业务通过不唯一索引访问数据时，需要考虑通过该索引值返回的记录稠密度，原则上可能的稠密度最大不能高于0.2，如果稠密度太大，则不合适建立索引了。
- 需要联合索引(或联合主键)的数据库要注意索引的顺序。SQL语句中的匹配条件也要跟索引的顺序保持一致。
- 索引的顺势不正确也可能导致严重的后果。
- 表中的多个字段查询作为查询条件，不含有其他索引，并且字段联合值不重复，可以在这多个字段上建唯一的联合索引，假设索引字段为 (a1,a2,...an),则查询条件(a1 op val1,a2 op val2,...am op valm)m<=n,可以用到索引，查询条件中字段的位置与索引中的字段位置是一致的。
- 遵循联合索引的建立原则。
- 重要业务访问数据表时，但不能通过索引访问数据时，应该确保顺序访问的记录数目是有限的，原则上不得多于10。

#### 引擎

- 若是指创建好的表，不能变动表结构的话，建议使用InnoDB引擎，多利用点内存，减轻磁盘IO负载，因为IO往往是数据库服务器的瓶颈。
- 若索引已创建的较好了，优先考虑修改类SQL语句，使他们更快些。
- 若是读为主，可以考虑打开query_cache，以及调整一些参数值：sort_buffer_size、read_buffer_size、read_rnd_buffer_size、join_buffer_size
- 一般情况可以选择MyISAM存储引擎，如果需要事务支持必须使用InnoDB存储引擎。

#### 查询语句

- 合理构造Query语句，慢SQL监控，分析慢日志，检查是否有大量的的子查询和关联查询、嵌套查询等，尽量避免使用这些查询， 使用连接（JOIN）来代替子查询(Sub-Queries)，使用联合(UNION)来代替手动创建的临时表。

- 限定数据的范围。务必禁止不带任何限制数据范围条件的查询语句。

    > 例如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内。

#### 订单表

- 主要通过订单id查询信息，可以按订单号/用户id/日期维度给拆分到多个库，在查询时携带库的条件，通过某个业务规则，直接定位到要查询的目标库。

- 如果是CRM客户关系管理系统 ，不直接使用订单号直接查询，而是一个范围查询，返回一个列表集合。此时不适合用分库分表，因为需要对各库的查询结果集进行union，使得性能反而下降。

#### 缓存

- mysql自带的query cache，对应用基本完全透明，但会受限于本机，而且只缓存查询结果，充分利用二级缓存减少数据库I/O操作。对数据库连接池，mybatis，hiberante二级缓存充分利用上。尽量使用顺序IO代替随机IO。
- 可以用memcache做缓存，redis用于需要持久化的场景，memcache和redis可以缓存一些加工后的数据。
- 缓存对于应用不是完全透明的，除非用Django这种成熟框架，而且缓存粒度很大。需要考虑如何保证缓存里的数据始终正确、写数据前还是后失效缓存、缓存挂了/写多读少导致缓存命中率低/数据过热导致流量压到后端mysql了怎么办、流量压倒后端mysql了怎么办、数据量大或QPS大时分片及HA的问题。

#### 复制/读写分离

- 经典的数据库拆分方案，主库负责写，从库负责读。
- 在应用层面或使用第三方工具（如360的atlas）做主从复制、主主复制、读写分离。实现备份、高可用、负载均衡。
- 节点少的情况下，主备，主备几乎适用于大多数场景，甚至不论数据大小。前面加Keepalived+HAProxy等组件，失效自动切换。
- 节点多的情况下，一是考虑多级备份，减轻主的压力。其次可以引入第三方组件，接管主节点的备份工作。主主不推荐，一是需要考虑数据冲突的情况，比如错开id，同时操作数据后的冲突解决。其次如果强一致会导致延迟增加，如果有节点挂了，需要等到超时才返回。
- LVS+HAProxy做一下HA。

#### 切分

- 包括垂直切分和水平切分，实现方式上又包括分库、分表。推荐。

- 根据数据库里面数据表的相关性进行拆分。 简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。 

    垂直切分保证业务的独立性，防止不同业务争抢资源，毕竟业务是有优先级的。垂直切分一般都要做，只不过业务粒度大小而已。根据业务垂直切分。业务内部分库、分表。一般都需要修改应用。除分表外，其余实现不是很复杂。有第三方组件可用，但通用高效又灵活的方式，还是自己写client。

    垂直拆分的优点： 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。

    垂直拆分的缺点： 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂。

    > 例如：用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。

- 水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。

    > 例如：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。

    保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。 

    水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 水平拆分最好分库 。

    水平拆分能够 支持非常大的数据量存储，应用端改造也少，但分片事务难以解决，跨节点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐 尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度 ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。

    水平切分主要用于突破单机瓶颈。除了主主外，只有切分能真正做到将负载分配下去。切分后也可对不同片数据进行不同优化。如按时间切分，超过一定时间数据不允许修改，就可以引入压缩了，数据传输及读取减少很多。水平拆分有一定难度，但如果将来一定会到这个规模，又可能用到，建议越早做越好。因为对应用的改动较大，而且迁移成本高。

    数据库分片的两种常见方案：

    - 客户端代理： 分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。 当当网的 Sharding**-**JDBC、阿里的TDDL是两种比较常用的实现。
    - 中间件代理**：** 在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。 我们现在谈的 Mycat 、360的Atlas、网易的DDB等等都是这种架构的实现。

- 分库有是经常用的，就算当前压力小，也尽量分出几个逻辑库出来。等规模上去了，很方便就迁移扩展。

- MySQL 是关系数据库，数据库表之间的关系从一定的角度上映射了业务逻辑。任何分库分表的行为都会在某种程度上提升业务逻辑的复杂度，数据库除了承载数据的存储和访问外，协助业务更好的实现需求和逻辑也是其重要工作之一。分库分表会带来数据的合并，查询或者更新条件的分离，事务的分离等等多种后果，业务实现的复杂程度往往会翻倍或者指数级上升。所以，在分库分表之前，不要为分而分，去做其他力所能及的事情吧，例如升级硬件，升级网络，升级数据库版本，读写分离，负载均衡等等。

- 对数据库的备份。如果单表或者单个实例太大，在做备份的时候需要大量的磁盘IO或者网络IO资源。例如1T的数据，网络传输占用50MB的时候，需要20000秒才能传输完毕，在此整个过程中的维护风险都是高于平时的。我们在Qunar的做法是给所有的数据库机器添加第二块网卡，用来做备份，或者SST，Group Communication等等各种内部的数据传输。1T的数据的备份，也会占用大量的磁盘IO，如果是SSD还好，当然这里忽略某些厂商的产品在集中IO的时候会出一些BUG的问题。如果是普通的物理磁盘，则在不限流的情况下去执行xtrabackup，该实例基本不可用。

- 对数据表的修改。如果某个表过大，对此表做DDL的时候，MySQL会锁住全表，这个时间可能很长，在这段时间业务不能访问此表，影响甚大。解决的办法有类似腾讯游戏DBA自己改造的可以在线秒改表，不过他们目前也只是能添加字段而已，对别的DDL还是无效；或者使用pt-online-schema-change，当然在使用过程中，它需要建立触发器和影子表，同时也需要很长很长的时间，在此操作过程中的所有时间，都可以看做是风险时间。把数据表切分，总量减小，有助于改善这种风险。

- 整个表热点，数据访问和更新频繁，经常有锁等待，你又没有能力去修改源码，降低锁的粒度，那么只会把其中的数据物理拆开，用空间换时间，变相降低访问压力。

- 表设计不合理时，需要对某些字段垂直拆分。例如user表的last_login_time，用户很活跃导致表不断的被update，压力非常大。

- 访问频率较低的大字段拆分出数据表。有些大字段占用空间多，访问频率较其他字段明显要少很多，这种情况进行拆分，频繁的查询中就不需要读取大字段，造成IO资源的浪费。如user表的personal_info基本不查询却是text占用很大空间。

- 某些数据表出现了无穷增长时。各种的评论，消息，日志记录。这个时候增加存储、提升机器配置已经苍白无力了，水平切分是最佳实践。拆分的标准很多，按用户的，按时间的，按用途的。

- 安全性和可用性的考虑。鸡蛋不要放在一个篮子里，不希望数据库出问题，但希望在出问题时影响到的用户比例越少越好。水平切分可以解决这个问题，把用户，库存，订单等等本来同统一的资源切分掉，每个小的数据库实例承担一小部分业务，这样整体的可用性就会提升。

- 业务耦合性考虑。对于完全无关的业务，虽然每个业务的数据量可能不太大，放在一个MySQL实例中完全没问题，但开发水平不齐，导致一方业务搞挂了数据库，另一方业务也受影响。

## 规范

### 命令语句

- 所有数据库对象名称必须使用小写字母并用下划线分割。
- 所有数据库对象名称禁止使用 MySQL 保留关键字（如果表名中包含关键字查询时，需要将其用单引号括起来）。
- 数据库对象的命名要能做到见名识意，并且最后不要超过 32 个字符。
- 临时库表必须以 tmp_为前缀并以日期为后缀，备份表必须以 bak_为前缀并以日期 (时间戳) 为后缀。
- 所有存储相同数据的列名和列类型必须一致（一般作为关联列，如果查询时关联列类型不一致会自动进行数据类型隐式转换，会造成列上的索引失效，导致查询效率降低）。

### 数据库设计

- 所有表必须使用 Innodb 存储引擎。

    没有特殊要求（即 Innodb 无法满足的功能如：列存储，存储空间数据等）的情况下，所有表必须使用 Innodb 存储引擎（MySQL5.5 之前默认使用 Myisam，5.6 以后默认的为 Innodb）。Innodb 支持事务，支持行级锁，更好的恢复性，高并发下性能更好。

- 数据库和表的字符集统一使用 UTF8。

    兼容性更好，统一字符集可以避免由于字符集转换产生的乱码，不同的字符集进行比较前需要进行转换会造成索引失效，如果数据库中有存储 emoji 表情的需要，字符集需要采用 utf8mb4 字符集。

- 所有表和字段都需要添加注释。

    使用 comment 从句添加表和列的备注，从一开始就进行数据字典的维护。

- 尽量控制单表数据量的大小,建议控制在 500 万以内。

    500 万并不是 MySQL 数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小。

- 谨慎使用 MySQL 分区表。

    分区表在物理上表现为多个文件，在逻辑上表现为一个表。谨慎选择分区键，跨分区查询效率可能更低。建议采用物理分表的方式管理大数据。

- 尽量做到冷热数据分离，减小表的宽度。

    MySQL 限制每个表最多存储 4096 列，并且每一行数据的大小不能超过 65535 字节。

    减少磁盘 IO，保证热数据的内存缓存命中率。表越宽，把表装载进内存缓冲池时所占用的内存也就越大，也会消耗更多的 IO。

    更有效的利用缓存，避免读入无用的冷数据。

    经常一起使用的列放到一个表中，避免更多的关联操作。

- 禁止在表中建立预留字段。

    预留字段的命名很难做到见名识义。

    预留字段无法确认存储的数据类型，所以无法选择合适的类型。

    对预留字段类型的修改，会对表进行锁定。

- 禁止在数据库中存储图片、文件等大的二进制数据。

    通常文件很大，会短时间内造成数据量快速增长，数据库进行数据库读取时，通常会进行大量的随机 IO 操作，文件很大时，IO 操作很耗时。通常存储于文件服务器，数据库只存储文件地址信息。

- 禁止在线上做数据库压力测试。

- 禁止从开发环境,测试环境直接连接生产环境数据库。

### 字段设计

- 优先选择符合存储需要的最小的数据类型。

    列的字段越大，建立索引时所需要的空间也就越大，这样一页中所能存储的索引节点的数量也就越少也越少，在遍历时所需要的 IO 次数也就越多，索引的性能也就越差。

    解决方法：

    - 将字符串转换成数字类型存储,如:将 IP 地址转换成整形数据。

        MySQL 提供了两个方法来处理 ip 地址：

        - inet_aton 把 ip 转为无符号整型 (4-8 位)
        - inet_ntoa 把整型的 ip 转为地址

        插入数据前，先用 inet_aton 把 ip 地址转为整型，可以节省空间，显示数据时，使用 inet_ntoa 把整型的 ip 地址转为地址显示即可。

    - 对于非负型的数据 (如自增 ID,整型 IP) 来说,要优先使用无符号整型来存储。

        无符号相对于有符号可以多出一倍的存储空间。VARCHAR(N) 中的 N 代表的是字符数，而不是字节数，使用 UTF8 存储 255 个汉字 Varchar(255)=765 个字节。过大的长度会消耗更多的内存。

        ```
        SIGNED INT -2147483648~2147483647
        UNSIGNED INT 0~4294967295
        ```

- 避免使用 TEXT,BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据。

    建议把 BLOB 或是 TEXT 列分离到单独的扩展表中。

    MySQL 内存临时表不支持 TEXT、BLOB 这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，MySQL 还是要进行二次查询，会使 sql 性能变得很差，但是不是说一定不能使用这样的数据类型。

    如果一定要使用，建议把 BLOB 或是 TEXT 列分离到单独的扩展表中，查询时一定不要使用 select * 而只需要取出必要的列，不需要 TEXT 列的数据时不要对该列进行查询。

- TEXT 或 BLOB 类型只能使用前缀索引

    MySQL对索引字段长度有限制，所以 TEXT 类型只能使用前缀索引，并且 TEXT 列上是不能有默认值的。

- 避免使用 ENUM 类型。

    修改 ENUM 值需要使用 ALTER 语句。

    ENUM 类型的 ORDER BY 操作效率低，需要额外操作。

    禁止使用数值作为 ENUM 的枚举值。

- 尽可能把所有列定义为 NOT NULL。

    索引 NULL 列需要额外的空间来保存，所以要占用更多的空间。

    进行比较和计算时要对 NULL 值做特别的处理。

- 使用 TIMESTAMP(4 个字节) 或 DATETIME 类型 (8 个字节) 存储时间。

    TIMESTAMP 存储的时间范围 1970-01-01 00:00:01 ~ 2038-01-19-03:14:07。

    TIMESTAMP 占用 4 字节和 INT 相同，但比 INT 可读性高。

    超出 TIMESTAMP 取值范围的使用 DATETIME 类型存储。

    不应用字符串存储日期型的数据，缺点是：

    - 无法用日期函数进行计算和比较
    - 用字符串存储日期要占用更多的空间

- 同财务相关的金额类数据必须使用 decimal 类型

    非精准浮点：float、double

    精准浮点：decimal

    Decimal 类型为精准浮点数，在计算时不会丢失精度。占用空间由定义的宽度决定，每 4 个字节可以存储 9 位数字，并且小数点要占用一个字节。可用于存储比 bigint 更大的整型数据。

### 索引设计

- 限制每张表上的索引数量,建议单张表索引不超过 5 个。

    索引并不是越多越好！索引可以提高效率同样可以降低效率。

    索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率。

    因为 MySQL 优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加 MySQL 优化器生成执行计划的时间，同样会降低查询性能。

- 禁止给表中的每一列都建立单独的索引

    5.6 版本之前，一个 sql 只能使用到一个表中的一个索引，5.6 以后，虽然有了合并索引的优化方式，但是还是远远没有使用一个联合索引的查询方式好。

- 每个 Innodb 表必须有个主键

    Innodb 是一种索引组织表，按照主键索引的顺序来组织表，数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种。

    不要使用更新频繁的列作为主键，不适用多列主键（相当于联合索引）

    不要使用 UUID,MD5,HASH,字符串列作为主键（无法保证数据的顺序增长）

    主键建议使用自增 ID 值

- 常见索引列建议

    出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列

    包含在 ORDER BY、GROUP BY、DISTINCT 中的字段

    并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好

    多表 join 的关联列

- 如何选择索引列的顺序

    建立索引的目的是：希望通过索引进行数据查找，减少随机 IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。

    区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数）

    尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好）

    使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引）

- 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间）

    重复索引示例：primary key(id)、index(id)、unique index(id)

    冗余索引示例：index(a,b,c)、index(a,b)、index(a)

- 对于频繁的查询优先考虑使用覆盖索引

    覆盖索引：包含了所有查询字段 (where,select,ordery by,group by 包含的字段) 的索引。

    覆盖索引的好处：

    - 避免 Innodb 表进行索引的二次查询: Innodb 是以聚集索引的顺序来存储的，对于 Innodb 来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了 IO 操作，提升了查询效率。
    - 可以把随机 IO 变成顺序 IO 加快查询效率:** 由于覆盖索引是按键值的顺序存储的，对于 IO 密集型的范围查找来说，对比随机从磁盘读取每一行的数据 IO 要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的 IO 转变成索引查找的顺序 IO。

- 索引 SET 规范

    尽量避免使用外键约束。不建议使用外键约束（foreign key），但一定要在表与表之间的关联键上建立索引。外键可用于保证数据的参照完整性，但建议在业务端实现。外键会影响父表和子表的写操作从而降低性能。

### SQL开发

- 建议使用预编译语句进行数据库操作。

    预编译语句可以重复使用这些计划，减少 SQL 编译所需要的时间，还可以解决动态 SQL 所带来的 SQL 注入的问题。只传参数，比传递 SQL 语句更高效。相同语句可以一次解析，多次使用，提高处理效率。

- 避免数据类型的隐式转换

    隐式转换会导致索引失效

    > 例如：
    >
    > ```sql
    > select name,phone from customer where id = '111';
    > ```

- 充分利用表上已经存在的索引

    避免使用双%号的查询条件。如：`a like '%123%'`，（如果无前置%,只有后置%，是可以用到列上的索引的）。一个 SQL 只能利用到复合索引中的一列进行范围查询。如：有 a,b,c 列的联合索引，在查询条件中有 a 列的范围查询，则在 b,c 列上的索引将不会被用到。

    在定义联合索引时，如果 a 列要用到范围查找的话，就要把 a 列放到联合索引的右侧，使用 left join 或 not exists 来优化 not in 操作，因为 not in 也通常会使用索引失效。

- 数据库设计时，应该要对以后扩展进行考虑

- 程序连接不同的数据库使用不同的账号，禁止跨库查询。

    为数据库迁移和分库分表留出余地。降低业务耦合度。避免权限过大而产生的安全风险。

- 禁止使用 SELECT * 必须使用 SELECT <字段列表> 查询。

    消耗更多的 CPU 和 IO 以网络带宽资源。无法使用覆盖索引。可减少表结构变更带来的影响。

- 禁止使用不含字段列表的 INSERT 语句

    不推荐：

    ```sql
    insert into values ('a','b','c');
    ```

    应使用：

    ```sql
    insert into t(c1,c2,c3) values ('a','b','c');
    ```


- 避免使用子查询，可以把子查询优化为 join 操作

    通常子查询在 in 子句中，且子查询中为简单 SQL(不包含 union、group by、order by、limit 从句) 时,才可以把子查询转化为关联查询进行优化。

    子查询性能差的原因是，子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大。

    由于子查询会产生大量的临时表也没有索引，所以会消耗过多的 CPU 和 IO 资源，产生大量的慢查询。

- 避免使用 JOIN 关联太多的表。

    对于 MySQL 来说，是存在关联缓存的，缓存的大小可以由 join_buffer_size 参数进行设置。

    在 MySQL 中，对于同一个 SQL 多关联（join）一个表，就会多分配一个关联缓存，如果在一个 SQL 中关联的表越多，所占用的内存也就越大。

    如果程序中大量的使用了多表关联的操作，同时 join_buffer_size 设置的也不合理的情况下，就容易造成服务器内存溢出的情况，就会影响到服务器数据库性能的稳定性。

    同时对于关联操作来说，会产生临时表操作，影响查询效率，MySQL 最多允许关联 61 个表，建议不超过 5 个。

- 减少同数据库的交互次数。

    数据库更适合处理批量操作，合并多个相同的操作到一起，可以提高处理效率。

- 对应同一列进行 or 判断时，使用 in 代替 or。

    in 的值不要超过 500 个，in 操作可以更有效的利用索引，or 大多数情况下很少能利用到索引。

- 禁止使用 order by rand() 进行随机排序

    order by rand() 会把表中所有符合条件的数据装载到内存中，然后在内存中对所有数据根据随机生成的值进行排序，并且可能会对每一行都生成一个随机值，如果满足条件的数据集非常大，就会消耗大量的 CPU 和 IO 及内存资源。推荐在程序中获取一个随机值，然后从数据库中获取数据的方式。

- WHERE 从句中禁止对列进行函数转换和计算。

    对列进行函数转换或计算时会导致无法使用索引。

    不推荐：

    ```sql
    where date(create_time)='20190101'
    ```

    推荐：

    ```sql
    where create_time >= '20190101' and create_time < '20190102'
    ```


- 在明显不会有重复值时使用 UNION ALL 而不是 UNION

    UNION 会把两个结果集的所有数据放到临时表中后再进行去重操作。UNION ALL 不会再对结果集进行去重操作。

- 拆分复杂的大 SQL 为多个小 SQL。

    大 SQL 逻辑上比较复杂，需要占用大量 CPU 进行计算的 SQL。MySQL 中，一个 SQL 只能使用一个 CPU 进行计算。SQL 拆分后可以通过并行执行来提高处理效率。

### 数据库操作行为

- 超 100 万行的批量写 (UPDATE,DELETE,INSERT) 操作,要分批多次进行操作。

    大批量操作可能会造成严重的主从延迟。主从环境中，大批量操作可能会造成严重的主从延迟，大批量的写操作一般都需要执行一定长的时间，而只有当主库上执行完成后，才会在其他从库上执行，所以会造成主库与从库长时间的延迟情况。

    binlog 日志为 row 格式时会产生大量的日志。大批量写操作会产生大量日志，特别是对于 row 格式二进制数据而言，由于在 row 格式中会记录每一行数据的修改，我们一次修改的数据越多，产生的日志量也就会越多，日志的传输和恢复所需要的时间也就越长，这也是造成主从延迟的一个原因。

    避免产生大事务操作。大批量修改数据，一定是在一个事务中进行的，这就会造成表中大批量数据进行锁定，从而导致大量的阻塞，阻塞会对 MySQL 的性能产生非常大的影响。特别是长时间的阻塞会占满所有数据库的可用连接，这会使生产环境中的其他应用无法连接到数据库，因此一定要注意大批量写操作要进行分批

- 对于大表使用 pt-online-schema-change 修改表结构。

    避免大表修改产生的主从延迟，避免在对表字段进行修改时进行锁表。

    对大表数据结构的修改一定要谨慎，会造成严重的锁表操作，尤其是生产环境，是不能容忍的。

    pt-online-schema-change 它会首先建立一个与原表结构相同的新表，并且在新表上进行表结构的修改，然后再把原表中的数据复制到新表中，并在原表中增加一些触发器。把原表中新增的数据也复制到新表中，在行所有数据复制完成之后，把新表命名成原表，并把原来的表删除掉。把原来一个 DDL 操作，分解成多个小的批次进行。

- 禁止为程序使用的账号赋予 super 权限。

    当达到最大连接数限制时，还运行 1 个有 super 权限的用户连接。super 权限只能留给 DBA 处理问题的账号使用。

- 对于程序连接数据库账号,遵循权限最小原则。

    程序使用数据库账号只能在一个 DB 下使用，不准跨库。程序使用的账号原则上不准有 drop 权限
