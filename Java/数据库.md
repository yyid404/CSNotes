# 数据库

关系型数据库：存储数据本身及数据之间的关系，把复杂的数据结构以二维关系表的形式存储。

非关系型数据库：作为关系型数据库的一个有效补充，并非是要否定关系型数据库。适合数据模型较简单，灵活性更强，对数据库性能要求较高，不需高度的数据一致性，对于给定key，比较容易映射复杂值的环境。

## JDBC

​		Java Data Base Connectivity。SUN公司为了简化、统一对数据库的操作，定义了一套Java操作数据库的规范，即Java定义的访问数据库的接口，这套接口由数据库厂商去实现，开发人员只需学习JDBC接口，并通过JDBC加载具体数据库软件的驱动，即实现类，就可以操作数据库。

### 操作

#### statement

```
Statement statement=connection.createStatement();
String sql="SQL语句"; 
ResultSet resultSet=statement.executeQuery(sql);
while(resultSet.next()){
	//根据获取列的数据类型，分别调用rs的相应方法。
	//映射到java对象中
}
```

#### prepareStatement

​		将SQL命令语句与参数分开处理先把SQL命令传到数据库中进行预编译，生成相应的数据库命令。再获取SQL中的参数，然后真正执行该sql语句。用户输入的参数，只被当做参数而非命令来解析，就可以避免数据库注入这样的问题发生。单次执行PreparedStatement需要与数据库通信两次，效率相对于单次执行Statement要低**。**

```
connection.prepareStatement(SQL语句);//SQL语句中用?当作占位符，等待用户输入的信息来进行填充。
prepareStatement.setString(1,username);
```

#### 批处理

​		rewriteBatchedStatements=true，开启批量处理，若不开启，MySQL的批处理默认为单条执行，即没有达到批量插入的效果。

​		Statement可执行多条不同类型的SQL语句，每条SQL语句单独执行。SQL语句没有预编译，当向数据库发送多条语句相同，但仅参数不同的SQL语句时，需重复写上很多条SQL语句。

​		PrepareStatement第一次需执行一次预编译，之后不再编译，故每个只能执行同一类型的SQL语句。与数据库通信次数在批量操作时，PreparedStatment的通信次数远少于Statment。只能应用在SQL语句相同，但参数不同的批处理中。

```
statement.addBatch(SQL)

preparedStatement.addBatch(SQL)

executeBatch()//执行批处理命令
clearBatch()//清除批处理命令
```

### 事务	

​		数据库默认开启事务，即自动提交。当JDBC程序向数据库获得一个Connection对象时，默认情况下这个Connection对象会自动向数据库提交commit在它上面发送的SQL语句。需关闭默认提交方式，让多条SQL在一个事务中执行。

```
connection.setAutoCommit(false)//设置为手动提交
connection.startTransaction()//开启事务
connection.setSavepoint()//设置事务回滚点
connection.rollback()//回滚事务，数据库状态回滚到start transcation开启时的状态。事务中异常不要抛，利用catch捕获进行回滚。回滚后必须要提交。若传入savepoint参数，可回滚到设置好的回滚点。
connection.commit()//提交事务
```

### 连接池

​		负责分配、管理、释放数据库连接。允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个。释放空闲时间超过最大空闲时间的数据库连接来避免因为没有释放数据库连接而引起的数据库连接遗漏。明显提高对数据库操作的性能。

​		应用程序直接获取连接的弊端是，用户每次请求都需要向数据库获得连接，数据库创建连接通常需要消耗相对较大的资源，创建时间也较长。极大的浪费数据库的资源，极易造成数据库服务器内存溢出、宕机。使用数据库连接池优化程序性能，用从连接池中获得的连接与数据库通迅。

​		实现Connection接口，借助现有的具体实现类重写接口中的所有抽象方法，再具体重写close()方法，使其效果为return pool而不是真正的close。

## DBUtils

​		Apache组织提供的一个开源JDBC工具类库，对JDBC进行简单封装，减少代码量。

```
QueryRunner runner = new QueryRunner(DataSource ds,…);
```

## MyBatis

### MyBatis简介

​		Mybatis是一个半ORM（对象关系映射）框架，内部封装了JDBC，开发时只需关注SQL语句本身，不需花费精力去处理加载驱动、创建连接、创建 statement 等繁杂的过程。

#### 适用场景

​		适用于专注于sql本身，足够灵活的DAO层解决方案，对性能要求很高，或者需求变化较多的项目。

#### 优缺点

优点：

1. 基于SQL语句编程，灵活，不会对应用程序或数据库的现有设计造成任何影响。
2. sql写在xml里，解除sql与程序代码的耦合，便于统一管理。
3. 提供xml标签，支持编写动态sql语句，可重用。
4. 与JDBC相比，减少了50%以上的代码量，消除了JDBC大量冗余的代码，不需手动开关连接。
5. 很好的与各种数据库兼容，使用JDBC来连接数据库，只要JDBC支持的数据库，Mybatis都支持。
6. 与Spring很好的集成。
7. 提供映射标签，支持对象与数据库的ORM字段关系映射，提供对象关系映射标签，支持对象关系组件维护。

缺点：

1. SQL语句的编写工作量较大。
2. SQL语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。

#### MyBatis和Hibernate的区别

**MyBatis**：半ORM框架，需要自己编写Sql语句。编写原生态sql，可以严格控制sql执行性能，灵活度高。无法做到数据库无关性，当需要实现支持多种数据库的软件时，需自定义多套sql映射文件，大大提升了工作量。

**Hibernate**：全自动ORM映射工具，使用Hibernate查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。Hibernate的对象/关系映射能力强，数据库无关性好，对于关系模型要求高的软件，如果用hibernate开发可以节省很多代码，提高效率。

### 配置

<'properties>：全局变量。name属性和value属性。可添加在配置文件中，添加resource属性，值为配置文件相对于当前应用的目录。用${...}引用全局变量。

<'environments>：配置数据源

<'mappers>：配置映射文件。resource属性为映射文件相对于classpath目录的相对路径；url属性为加载文件下的映射文件。class属性为接口全类名。namespace属性为命名空间。

<'package>：name属性为接口或映射文件所在的包目录

<'typeAliases>：别名

1. <'typeAlias>：为单个JavaBean设置别名。type属性为全类名，alias属性为别名。可简化returnType属性原本要使用的全类名。

2. <'package>：批量为包下所有类配置别名。name属性为包的全名，别名默认为该包下类名的小写形式，基本类型则为_类型名。

### 使用

#### 关系映射方式

##### 执行

​		MyBatis可以通过xml文件或注解的方式将要执行的各种statement配置起来，并通过java对象和statement中sql的动态参数进行映射生成最终执行的 sql 语句，最后由 mybatis 框架执行sql并将结果映射为java对象并返回。

##### 返回

​		有了列名与属性名的映射关系后，Mybatis通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。

###### 返回新插入的这条记录的主键的方法

​		采用自增长策略，自动生成的键值在insert方法执行完后可以被设置到传入的参数对象中。

```
<insert id="insertname" usegeneratedkeys="true" keyproperty="id"> 
	insert into names (name) values (#{name})
</insert>
```

##### 输入映射

**value**：多个参数时，#{}里可填param和arg，arg索引从0开始，param从1开始。

**Bean**：单个Bean，#{}里填成员变量名；多个Bean，#{}里填argN.成员变量名或paramN.成员变量名。

**Map**：单个Map，#{}里填key。

**多个混合类型**：用param或arg，根据对应类型添加.后面的。

**注解**：传入参数时在参数前用@Param(“别名”)给传入的参数起别名。

##### 输出映射

**resultType**：

1. 单个值：resultType为string，Mapper接口中用String接收。

2. 多个值：resultType为string，Mapper接口中用List<'String>接收。

3. 单个Bean：resultType为Bean的全类名，Mapper接口中用类名接收，若数据库中的列名与Bean中的成员变量名（实质为set()方法）不匹配，则用as给单个属性起别名。

4. 多个Bean：resultType为Bean的全类名，Mapper接口中用List<'Bean>或Bean[]接收。

**resultMap**：用于封装JavaBean，让查询结果的列名和Bean的成员变量名产生映射关系。<'resultMap>标签相当于全局变量，<‘select’>标签均可使用。

1. id属性：标识

2. type属性：设置该resultMap最终的封装类型

3. <'id>标签：只可主键可使用

4. <'result>标签：通用；property属性为Bean的成员变量名；column属性为数据库表的列名。

###### 实体类中的属性名和表中的字段名不一样时

1. SQL语句中定义字段的别名，让字段名的别名和实体类的属性名一致。

2. 通过<'resultMap>来映射字段名和实体类属性名的一一对应的关系，property为实体类属性名，column为数据表中的属性。用id属性来映射主键字段；用result属性来映射非主键字段。

#### 查询方式

##### 分次查询

​		先查一个表,根据这个表里面的结果的外键id，去再另外一个表里面查询数据,也是通过配置collection，但另外一个表的查询通过select节点配置。

1. <'association>标签：property属性值为需要进行第二次查询的小Bean在大Bean中的成员变量名；column属性值为传递给第二次查询的参数的当前查询结果的列属性；select属性值为第二次查询的命名空间+id。
2. sql语句中的limit字段，分次查询为限制左表的记录数。

##### 连接查询

​		几个表联合查询，只查询一次,通过在resultMap里面的collection节点配置一对多的类就可以完成。

1. <'association>标签：property属性值为需要进行第二次查询的小Bean在大Bean中的成员变量名；javaType属性值为该小Bean成员变量的全类名；

2. <'result>标签的column属性值为查询结果的列名，property属性值为小Bean封装类型的成员变量名。
3. sql语句中的limit字段，连接查询为限制结果的总记录数。

#### Mapper接口

##### 接口绑定

​		在MyBatis中任意定义接口，然后把接口里面的方法和SQL语句绑定，我们直接调用接口方法就可以，这样比起原来了SqlSession提供的方法我们可以有更加灵活的选择和设置。当Sql语句比较简单时候，用注解绑定，当SQL语句比较复杂时候，用xml绑定，一般用xml绑定的比较多。

###### 绑定方式

**通过注解绑定**：在接口的方法上面加上 @Select、@Update等注解，里面包含Sql语句来绑定。

**通过xml里面写SQL来绑定**：要指定xml映射文件里面的namespace必须为接口的全路径名。

##### 工作原理

​		Mapper接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Mapper接口生成代理对象proxy，代理对象会拦截接口方法，转而执行MapperStatement所代表的sql，然后将sql执行结果返回。

​		Mapper接口没有实现类，维护了一个Map<String,MapperStatement>，当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MapperStatement，所以Mapper接口里的方法不能重载。在Mybatis中，每一个<'select>、<'insert>、<'update>、<'delete>标签，都会被解析为一个MapperStatement对象。

##### 规范

1. Mapper接口方法名和mapper.xml中定义的每个sql的id相同
2. Mapper接口方法的输入参数类型和mapper.xml中定义的每个sql 的parameterType的类型相同
3. Mapper接口方法的输出参数类型和mapper.xml中定义的每个sql的resultType的类型相同
4. Mapper.xml文件中的namespace即是mapper接口的类全限名。

##### SqlMapConfig.xml配置

properties：属性

settings：配置

typeAliases：类型别名

typeHandlers：类型处理器

objectFactory：对象工厂

plugins：插件

environments：环境集合属性对象

environment：环境子属性对象

transactionManager：事务管理

dataSource：数据源

mappers：映射器

##### mapper编写

**方式一：接口实现类继承SqlSessionDaoSupport**

1. 定义mapper接口

2. 接口实现类：继承SqlSessionDaoSupport。mapper方法中可以this.getSqlSession()进行数据增删改查。

3. 配置文件：在sqlMapConfig.xml中配置mapper.xml的位置

    ```
    <mappers>
    
    	<mapper resource="mapper.xml文件的地址" />
    
    	<mapper resource="mapper.xml文件的地址" />
    
    </mappers>
    ```

4. Spring配置

    ```
    <bean id="..." class="mapper接口的实现类">
    
    	<property name="sqlSessionFactory" ref="sqlSessionFactory"></property>
    
    </bean>
    ```

**方式二：用org.mybatis.spring.mapper.MapperFactoryBean**

1. 在sqlMapConfig.xml中配置mapper.xml的位置，如果mapper.xml和mappre接口的名称相同且在同一个目录，这里可以不用配置。

    ```
    <mappers>
    
    	<mapper resource="mapper.xml文件的地址" />
    
    	<mapper resource="mapper.xml文件的地址" />
    
    </mappers>
    ```

2. 定义mapper接口

    1. mapper.xml中的namespace为mapper接口的地址

    2. mapper接口中的方法名和mapper.xml中的定义的statement的id保持一致

    3. Spring配置

        ```
        <bean id="" class="org.mybatis.spring.mapper.MapperFactoryBean">
        
        	<property name="mapperInterface"  value="mapper接口地址" /> 
        
        	<property name="sqlSessionFactory" ref="sqlSessionFactory" /> 
        
        </bean>
        ```

**方式三：使用mapper扫描器**

1. mapper.xml文件编写：mapper.xml中的namespace为mapper接口的地址；mapper接口中的方法名和mapper.xml中的定义的statement的id保持一致；如果将mapper.xml和mapper接口的名称保持一致则不用在sqlMapConfig.xml中进行配置。 

2. 定义mapper接口：注意mapper.xml的文件名和mapper的接口名称保持一致，且放在同一个目录

3. 配置mapper扫描器：

    ```
    <bean class="org.mybatis.spring.mapper.MapperScannerConfigurer">
    
    	<property name="basePackage" value="mapper接口包地址"></property>
    
    	<property name="sqlSessionFactoryBeanName" 		value="sqlSessionFactory"/> 
    
    </bean>
    ```

4. 使用扫描器后从spring容器中获取mapper的实现对象。

#### SQL注入

​		#{}是预编译处理，${}是字符串替换。Mybatis在处理#{}时，会将sql中的#{}替换为占位符?号，调用PreparedStatement的set方法来赋值；处理${}时，就是把${}替换成变量的值。SQL注入只能在编译过程起作用。使用#{}可以有效的防止SQL注入，提高系统安全性。$方式一般用于传入数据库对象，例如传入表名。

#### 动态SQL

##### 执行原理

​		根据表达式的值，完成逻辑判断并动态拼接sql语句。

##### 使用

<'where>：若<'where>标签后有一个多余的关系词and或or，则会省略掉该词，缺少关系词时不会自动补充。

<'if>：

1. test属性：值为true，则拼接该标签内的语句。gt大于，lt小于。

<'trim>：

1. prefix属性：在<'trim>标签内的内容最前面拼接这个值。
2. suffix属性：在<'trim>标签内的内容最后面拼接这个值。
3. prefixOverrides属性：若<'trim>标签内的内容最前面包含这个值，则将其去掉。
4. suffixOverrides属性：若<'trim>标签内的内容最后面包含这个值，则将其去掉。

<'choose>：

1. <'when>标签：相当于if，可写多个<'when>标签，相当于else if，
2. <'otherwise>标签：相当于else。

<'sql>：引入sql片段，相当于将耦合的sql语句提取为全局变量供引用，映射文件中的任意片段均可写入<'sql>标签。

<'include>：

1. refid属性：值为引用指定sql片段的id。

<'foreach>：

1. collection属性：若数组无注解，值为array；若List无注解，值为list；若有注解，值为@Param里的值。
2. item属性：值为集合中的单元起的标识名。
3. seperator属性：为每两个遍历的单元之间添加分隔符。
4. open属性：<'foreach>标签中最前面加上的值。
5. close属性：<'foreach>标签中最后面加上的值。

<'selectKey>：在原先的sql的基础上额外去执行一个sql语句。

1. order属性：值为before为前置执行，该selectKey将在<'insert>标签的内容最前执行，作用为将新插入的信息在<'insert>执行后立即取出其keyColumn属性封装进keyProperty属性，以便在Bean中回显；值为after为后置执行，该selectKey将在<'insert>标签的内容最后执行。
2. keyColumn属性：给查询结果起的列名。keyProperty属性为将查询结果重新赋值给原Bean中的属性。
3. resultType属性：keyProperty对应的类型，设置该查询结果封装的类型。

#### SqlSession

##### 常用对象

**sqlSession**：封装了connection，线程不安全，缺点是每次查询都需新启动一个查询会话sqlSession，使用session去执行sql语句。

**SqlSessionFactory**：线程安全

1. 建造FactoryBuilder
2. 根据配置文件制造factory，配置文件路径为相对于classpath目录的路径。
3. 启动sqlSession
4. 用sqlSession去调用sql语句，返回值为Object类型。执行的为增删改，需提交和关闭sqlSession。

##### 使用

1. 创建SqlSessionFactory

2. 通过SqlSessionFactory创建SqlSession

3. 通过sqlsession执行数据库操作

4. 调用session.commit()提交事务

5. 调用session.close()关闭会话

##### Test解耦

1. 方法上添加@Before注解，该方法会在任意的@Test方法执行前执行。
2. 方法上添加@After注解，该方法会在任意的@Test方法执行后执行。
3. 每一个@Test方法都需要一个新的sqlSession对象，所以@Before中只执行到提供sqlSessionFactory对象即可。

#### 批量插入

```
sqlsession sqlsession = sqlsessionfactory.opensession(executortype.batch);

namemapper mapper = sqlsession.getmapper(namemapper.class);

foreach遍历参数列表{ mapper.insertname(name); }
```

#### 分页

​		Mybatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的内存分页，而非物理分页。可以在sql内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。

##### 自定义分页插件

###### 运行原理

​		ParameterHandler、ResultSetHandler、StatementHandler、Executor这4种接口的插件，Mybatis使用JDK的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这4种接口对象的方法时，就会进入拦截方法，具体为InvocationHandler的invoke()方法，当然，只会拦截所指定的需要拦截的方法。

###### 编写方法

1. 实现Mybatis提供的Interceptor插件接口。
2. 复写intercept()方法，拦截方法内拦截待执行的sql，然后重写sql，根据dialect方言，添加对应的物理分页语句和物理分页参数。
3. 给插件编写注解，指定要拦截哪一个接口的哪些方法。
4. 在配置文件中配置编写的插件。

### 缓存

​		Mybatis首先去缓存中查询结果集，如果没有则查询数据库，如果有则从缓存取出返回结果集就不走数据库。Mybatis内部存储缓存使用一个HashMap，key为hashCode+sqlId+Sql语句。value为从查询出来映射生成的java对象。

#### 分类

**一级缓存**：基于PerpetualCache的HashMap本地缓存，其存储作用域为sqlSession。在同一个SqlSession中执行两次相同的SQL语句时，第一次执行完毕会将查询结果存入缓存中，第二次查询会直接从缓存中取数据，提高执行效率。调用修改(U)、添加(C)、删除(D)、执行commit()会清空一级缓存，避免脏读现象。当Session flush 或close之后，该Session中的所有Cache就将清空，默认打开一级缓存。

**二级缓存**：二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap 存储，不同在于其存储作用域为 Mapper，即同一个namespace的mapper.xml，可以跨SqlSession，并且可自定义存储源，如 Ehcache。默认不打开二级缓存，添加<'settings>标签，name属性为CacheEnabled，value属性为true，即开启二级缓存。当一个 sqlseesion 执行了一次 select 后，在关闭此 session 的时候，会将查询结果缓存到二级缓存。当另一个 sqlsession 执行 select 时，首先会在他自己的一级缓存中找，如果没找到，就回去二级缓存中找，找到了就返回，就不用再去数据库了。二级缓存会保存到本地磁盘中，需对其进行反序列化，使用二级缓存属性类需要实现Serializable接口，可在它的映射文件中添加<'cache>标签 。执行commit()关闭一级缓存时，二级缓存生效，调用修改(U)、添加(C)、删除(D)则清空二级缓存。

**Cache实现类**：https://www.cnblogs.com/jabnih/p/5705640.html

#### 缓存更新机制

​		当某一个作用域(一级缓存 Session/二级缓存Namespaces)的进行了C/U/D 操作后，默认该作用域下所有 select 中的缓存将被clear掉并重新更新，如果开启了二级缓存，则只根据配置判断是否刷新。

#### 延迟加载

​		把对用户信息的按需去查询就是延迟加载。 所以延迟加载即先从单表查询、需要时再从关联表去关联查询，大大提高数据库性能，因为查询单表要比关联查询多张表速度要快。

​		Mybatis仅支持association关联对象和collection关联集合对象的延迟加载，association指的就是一对一，collection指的就是一对多查询。

##### 原理

​		使用CGLIB创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用a.getB().getName()，拦截器invoke()方法发现a.getB()是null值，那么就会单独发送事先保存好的查询关联B对象的sql，把B查询上来，然后调用a.setB(b)，于是a的对象b属性就有值了，接着完成a.getB().getName()方法的调用。

##### 使用

​		在Mybatis配置文件中，可以配置是否启用延迟加载，添加<'settings>标签，name属性为lazyLoadingEnabled，value为true|false。默认不开启懒加载，当开启懒加载后，所有的分次查询均将使用懒加载。可在<'association>或<'collection>标签中添加fetchType属性，值为eager，即可使单个sql语句使用立即加载。

### 逆向工程

​		根据数据库帮我们生成代码（javabean、mapper接口、映射文件）

​		**Generator类**：运行后自动根据generatorConfig.xml配置文件中的信息生成与指定数据库相应的JavaBean、JavaBeanExample、BeanMapper。

### 源码

​		MyBatis框架是一种典型的交互式框架，先准备好交互的必要条件，然后构建一个交互的环境，在交互环境中划分会话，在会话中与数据库进行交互数据。MyBatis框架主要完成的是以下2件事情：

1. 根据JDBC规范建立与数据库的连接。
2. 通过反射打通Java对象与数据库参数交互之间相互转换的关系。

#### 模块　　

![img](https://img-blog.csdnimg.cn/20190124093442611.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BhbmppYW5sb25nV1VIQU4=,size_16,color_FFFFFF,t_70)

##### API接口层

1. SqlSession会话模块：session

##### 核心处理层

1. 配置解析：builder
2. SQL解析：scripting
3. SQL执行：executor
4. 参数设置
5. 主键生成
6. 结果集映射：mapping
7. 延迟加载
8. 插件模块：plugin
9. 游标模块：cursor

##### 基础模块层

1. 解析器模块：parsing
2. 反射模块：reflection
3. 异常模块：exceptions
4. 数据源模块：dataSource
5. 事务模块：transaction
6. 缓存模块：cache
7. 类型转化模块：type
8. 资源加载模块：io
9. 日志模块：logging
10. 注解模块：annotations
11. Binding模块：binding

##### 其他

1. JDBC模块：jdbc
2. Lang模块：lang

#### 主要的类

##### Configuration

​		MyBatis所有的配置信息都维持在Configuration对象之中。

##### SqlSession

​		作为MyBatis工作的主要顶层API，表示和数据库交互的会话，完成必要数据库增删改查功能。

##### DefaultSqlSession

​		sqlSessionFactory默认生成的SqlSession是DefaultSqlSession类型。DefaultSqlSession不是线程安全的不能在spring中作为单例使用。而SqlSessionTemplate是线程安全的，动态代理创建的sqlSessionProxy（实质是DefaultSqlSession）进行调用，其代理类是SqlSessionInterceptor，查看其invoke方法{getSqlSession()和closeSqlSession()方法，两个方法中去实现线程安全，在进来的时候通过ThreadLocal保存创建的SqlSessionHolder在对象TransactionSynchronicationManager中的，在执行完之后colse() 来确保线程安全。

1. selectList()方法

    ```
    // DefaultSqlSession
    public <E> List<E> selectList(String statement, Object parameter, RowBounds rowBounds) {
        try {
            MappedStatement ms = configuration.getMappedStatement(statement);
            // CURD操作是交给Excetor去处理的
            return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);
        } catch (Exception e) {
            throw ExceptionFactory.wrapException("Error querying database.  Cause: " + e, e);
        } finally {
            ErrorContext.instance().reset();
        }
    }
    ```

##### Executor

​		MyBatis执行器，是MyBatis 调度的核心，负责SQL语句的生成和查询缓存的维护。

##### CachingExecutor

​		在DefaultSqlSession.selectList中的各种CURD操作都是通多Executor进行的，这里executor的类型是CachingExecutor。

1. query(MappedStatement, Object, RowBounds, ResultHandler)方法

    ```
    // CachingExecutor 类
    public <E> List<E> query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException {
        BoundSql boundSql = ms.getBoundSql(parameterObject);  // 获取绑定的sql命令，比如"SELECT * FROM xxx"
        CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql);
        return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
    }
    ```

2. query(MappedStatement, Object, RowBounds, ResultHandler, CacheKey, BoundSql)方法

    ```
    // CachingExecutor 类
    @Override
    public <E> List<E> query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)
            throws SQLException {
        Cache cache = ms.getCache();
        if (cache != null) {
            flushCacheIfRequired(ms);
            if (ms.isUseCache() && resultHandler == null) {
                ensureNoOutParams(ms, parameterObject, boundSql);
                @SuppressWarnings("unchecked")
                List<E> list = (List<E>) tcm.getObject(cache, key);
                if (list == null) {
                    list = delegate.<E> query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
                    tcm.putObject(cache, key, list); // issue #578 and #116
                }
                return list;
            }
        }
        return delegate.<E> query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
    }
    ```

##### BaseExecutor

​		SimplyExecutor的父类。

1. query方法

    ```
    //BaseExecutor类
    @SuppressWarnings("unchecked")
    @Override
    public <E> List<E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
        ErrorContext.instance().resource(ms.getResource()).activity("executing a query").object(ms.getId());
        if (closed) {
            throw new ExecutorException("Executor was closed.");
        }
        if (queryStack == 0 && ms.isFlushCacheRequired()) {
            clearLocalCache();
        }
        List<E> list;
        try {
            queryStack++;
            /**
             * localCache是一级缓存，如果找不到就调用queryFromDatabase从数据库中查找
             */
            list = resultHandler == null ? (List<E>) localCache.getObject(key) : null;
            if (list != null) {
                handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);
            } else {
                list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);
            }
        } finally {
            queryStack--;
        }
        if (queryStack == 0) {
            for (DeferredLoad deferredLoad : deferredLoads) {
                deferredLoad.load();
            }
            // issue #601
            deferredLoads.clear();
            if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) {
                // issue #482
                clearLocalCache();
            }
        }
        return list;
    }
    ```

2. queryFromDatabase方法

    ```
    //BaseExecutor类
    private <E> List<E> queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
        List<E> list;
        localCache.putObject(key, EXECUTION_PLACEHOLDER);
        try {
            list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql);
        } finally {
            localCache.removeObject(key);
        }
        localCache.putObject(key, list);
        if (ms.getStatementType() == StatementType.CALLABLE) {
            localOutputParameterCache.putObject(key, parameter);
        }
        return list;
    }
    ```

##### SimplyExecutor

​		真正执行query操作的是SimplyExecutor代理来完成的。

1. doQuery方法

    ```
    // SimplyExecutor类
    public <E> List<E> doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException {
        Statement stmt = null;
        try {
            Configuration configuration = ms.getConfiguration();
            StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql);
            // 子流程1：SQL查询参数的设置
            stmt = prepareStatement(handler, ms.getStatementLog());
            // StatementHandler封装了Statement
            // 子流程2：SQL查询操作和结果集的封装
            return handler.<E>query(stmt);
        } finally {
            closeStatement(stmt);
        }
    }
    ```

2. prepareStatement方法

    ```
    // SimplyExecutor类
    private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException {
        Statement stmt;
        // 获取一个Connection
        Connection connection = getConnection(statementLog);
        stmt = handler.prepare(connection, transaction.getTimeout());
        handler.parameterize(stmt); // 设置SQL查询中的参数值
        return stmt;
    }
    ```

##### StatementHandler

​		封装了JDBC Statement操作，负责对JDBC statement 的操作，如设置参数、将Statement结果集转换成List集合。

##### PrepareStatementHandler

1. parameterize方法

    ```
    // PrepareStatementHandler类
    @Override
    public void parameterize(Statement statement) throws SQLException {
        parameterHandler.setParameters((PreparedStatement) statement);
    }
    ```

##### RoutingStatementHandler

1. query(Statement)方法

    ```
    // RoutingStatementHandler类
    @Override
    public <E> List<E> query(Statement statement) throws SQLException {
        return delegate.<E>query(statement);
    }
    ```

2. query(Statement)方法

    ```
    // RoutingStatementHandler类
    @Override
    public <E> List<E> query(Statement statement) throws SQLException {
        // 这里就到了熟悉的PreparedStatement了
        PreparedStatement ps = (PreparedStatement) statement;
        // 执行SQL查询操作
        ps.execute();
        // 结果交给ResultHandler来处理
        return resultSetHandler.<E> handleResultSets(ps);
    }
    ```

##### ParameterHandler

​		负责对用户传递的参数转换成JDBC Statement 所需要的参数，

##### DefaultParameterHandler

1. setParameters方法

    ```
    // DefaultParameterHandler类
    @Override
    public void setParameters(PreparedStatement ps) {
        ErrorContext.instance().activity("setting parameters").object(mappedStatement.getParameterMap().getId());
        List<ParameterMapping> parameterMappings = boundSql.getParameterMappings();
        if (parameterMappings != null) {
            for (int i = 0; i < parameterMappings.size(); i++) {
                ParameterMapping parameterMapping = parameterMappings.get(i);
                if (parameterMapping.getMode() != ParameterMode.OUT) {
                    Object value;
                    String propertyName = parameterMapping.getProperty();
                    if (boundSql.hasAdditionalParameter(propertyName)) { // issue #448 ask first for additional params
                        value = boundSql.getAdditionalParameter(propertyName);
                    } else if (parameterObject == null) {
                        value = null;
                    } else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) {
                        value = parameterObject;
                    } else {
                        MetaObject metaObject = configuration.newMetaObject(parameterObject);
                        value = metaObject.getValue(propertyName);
                    }
                    TypeHandler typeHandler = parameterMapping.getTypeHandler();
                    JdbcType jdbcType = parameterMapping.getJdbcType();
                    if (value == null && jdbcType == null) {
                        jdbcType = configuration.getJdbcTypeForNull();
                    }
                    try {
                        typeHandler.setParameter(ps, i + 1, value, jdbcType);
                    } catch (TypeException e) {
                        throw new TypeException("Could not set parameters for mapping: " + parameterMapping + ". Cause: " + e, e);
                    } catch (SQLException e) {
                        throw new TypeException("Could not set parameters for mapping: " + parameterMapping + ". Cause: " + e, e);
                    }
                }
            }
        }
    }
    ```

##### ResultSetHandler

​		负责将JDBC返回的ResultSet结果集对象转换成List类型的集合。

##### DefaultResultSetHandler

1. handleResultSets方法

    ```
    // DefaultResultSetHandler类（封装返回值，将查询结果封装成Object对象）
    @Override
    public List<Object> handleResultSets(Statement stmt) throws SQLException {
        ErrorContext.instance().activity("handling results").object(mappedStatement.getId());
    
        final List<Object> multipleResults = new ArrayList<Object>();
    
        int resultSetCount = 0;
        ResultSetWrapper rsw = getFirstResultSet(stmt);
    
        List<ResultMap> resultMaps = mappedStatement.getResultMaps();
        int resultMapCount = resultMaps.size();
        validateResultMapsCount(rsw, resultMapCount);
        while (rsw != null && resultMapCount > resultSetCount) {
            ResultMap resultMap = resultMaps.get(resultSetCount);
            handleResultSet(rsw, resultMap, multipleResults, null);
            rsw = getNextResultSet(stmt);
            cleanUpAfterHandlingResultSet();
            resultSetCount++;
        }
    
        String[] resultSets = mappedStatement.getResultSets();
        if (resultSets != null) {
            while (rsw != null && resultSetCount < resultSets.length) {
                ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]);
                if (parentMapping != null) {
                    String nestedResultMapId = parentMapping.getNestedResultMapId();
                    ResultMap resultMap = configuration.getResultMap(nestedResultMapId);
                    handleResultSet(rsw, resultMap, null, parentMapping);
                }
                rsw = getNextResultSet(stmt);
                cleanUpAfterHandlingResultSet();
                resultSetCount++;
            }
        }
    
        return collapseSingleResultList(multipleResults);
    }
    ```

2. handleResultSet方法

    ```
    // DefaultResultSetHandler类
    private void handleResultSet(ResultSetWrapper rsw, ResultMap resultMap, List<Object> multipleResults, ResultMapping parentMapping) throws SQLException {
        try {
            if (parentMapping != null) {
                handleRowValues(rsw, resultMap, null, RowBounds.DEFAULT, parentMapping);
            } else {
                if (resultHandler == null) {
                    DefaultResultHandler defaultResultHandler = new DefaultResultHandler(objectFactory);
                    handleRowValues(rsw, resultMap, defaultResultHandler, rowBounds, null);
                    multipleResults.add(defaultResultHandler.getResultList());
                } else {
                    handleRowValues(rsw, resultMap, resultHandler, rowBounds, null);
                }
            }
        } finally {
            // issue #228 (close resultsets)
            closeResultSet(rsw.getResultSet());
        }
    }
    ```

3. handleRowValues方法

    ```
    // DefaultResultSetHandler类
    public void handleRowValues(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler<?> resultHandler, RowBounds rowBounds, ResultMapping parentMapping) throws SQLException {
        if (resultMap.hasNestedResultMaps()) {
            ensureNoRowBounds();
            checkResultHandler();
            handleRowValuesForNestedResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping);
        } else {
            // 封装数据
            handleRowValuesForSimpleResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping);
        }
    }
    ```

4. handleRowValuesForSimpleResultMap方法

    ```
    // DefaultResultSetHandler类
    // 封装数据
    private void handleRowValuesForSimpleResultMap(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler<?> resultHandler, RowBounds rowBounds, ResultMapping parentMapping)
            throws SQLException {
        DefaultResultContext<Object> resultContext = new DefaultResultContext<Object>();
        skipRows(rsw.getResultSet(), rowBounds);
        while (shouldProcessMoreRows(resultContext, rowBounds) && rsw.getResultSet().next()) {
            ResultMap discriminatedResultMap = resolveDiscriminatedResultMap(rsw.getResultSet(), resultMap, null);
            Object rowValue = getRowValue(rsw, discriminatedResultMap);
            storeObject(resultHandler, resultContext, rowValue, parentMapping, rsw.getResultSet());
        }
    }
    ```

5. getRowValue方法

    ```
    // DefaultResultSetHandler类
    private Object getRowValue(ResultSetWrapper rsw, ResultMap resultMap) throws SQLException {
        final ResultLoaderMap lazyLoader = new ResultLoaderMap();
        // createResultObject为新创建的对象，数据表对应的类
        Object resultObject = createResultObject(rsw, resultMap, lazyLoader, null);
        if (resultObject != null && !hasTypeHandlerForResultObject(rsw, resultMap.getType())) {
            final MetaObject metaObject = configuration.newMetaObject(resultObject);
            boolean foundValues = !resultMap.getConstructorResultMappings().isEmpty();
            if (shouldApplyAutomaticMappings(resultMap, false)) {
                // 这里把数据填充进去，metaObject中包含了resultObject信息
                foundValues = applyAutomaticMappings(rsw, resultMap, metaObject, null) || foundValues;
            }
            foundValues = applyPropertyMappings(rsw, resultMap, metaObject, lazyLoader, null) || foundValues;
            foundValues = lazyLoader.size() > 0 || foundValues;
            resultObject = foundValues ? resultObject : null;
            return resultObject;
        }
        return resultObject;
    }
    ```

6. applyAutomaticMappings方法

    ```
    // DefaultResultSetHandler类（把ResultSet中查询结果填充到JavaBean中）
    private boolean applyAutomaticMappings(ResultSetWrapper rsw, ResultMap resultMap, MetaObject metaObject, String columnPrefix) throws SQLException {
        List<UnMappedColumnAutoMapping> autoMapping = createAutomaticMappings(rsw, resultMap, metaObject, columnPrefix);
        boolean foundValues = false;
        if (autoMapping.size() > 0) {
                    // 这里进行for循环调用，因为user表中总共有7项，所以也就调用7次
            for (UnMappedColumnAutoMapping mapping : autoMapping) {
                // 这里将esultSet中查询结果转换为对应的实际类型
                final Object value = mapping.typeHandler.getResult(rsw.getResultSet(), mapping.column);
                if (value != null) {
                    foundValues = true;
                }
                if (value != null || (configuration.isCallSettersOnNulls() && !mapping.primitive)) {
                    // gcode issue #377, call setter on nulls (value is not 'found')
                    metaObject.setValue(mapping.property, value);
                }
            }
        }
        return foundValues;
    }
    ```

##### MetaObject

1. setValue方法

    ```
    // MetaObject类
    public void setValue(String name, Object value) {
        PropertyTokenizer prop = new PropertyTokenizer(name);
        if (prop.hasNext()) {
            MetaObject metaValue = metaObjectForProperty(prop.getIndexedName());
            if (metaValue == SystemMetaObject.NULL_META_OBJECT) {
                if (value == null && prop.getChildren() != null) {
                    // don't instantiate child path if value is null
                    return;
                } else {
                    metaValue = objectWrapper.instantiatePropertyValue(name, prop, objectFactory);
                }
            }
            metaValue.setValue(prop.getChildren(), value);
        } else {
            objectWrapper.set(prop, value);
        }
    }
    ```

##### TypeHandler

​		负责java数据类型和jdbc数据类型之间的映射和转换

##### MappedStatement

​		MappedStatement维护了一条<select|update|delete|insert>节点的封装，

##### SqlSource

​		负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中，并返回

##### BoundSql

​		表示动态生成的SQL语句以及相应的参数信息

#### SQL执行

![img](http://img.blog.csdn.net/20141028140852531?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHVhbmxvdWlz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

1. 构建sqlSession工厂

    ```
    SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(is);
    ```

2. 获取sqlSession。sqlSessionFactory默认生成的SqlSession是DefaultSqlSession类型。

    ```
    SqlSession session = sqlSessionFactory.openSession();
    ```

3. 查询。selectOne()会调用DefaultSqlSession的selectList()。

    ```
    user = session.selectOne(statement, 1);
    ```

4. CURD操作是交给Excetor去处理的。DefaultSqlSession的selectList()执行了Excetor的query()。
5. executor的类型是CachingExecutor，跳转到其中的query方法。
6. CachingExecutor的query方法中，getBoundSql方法是为了获取绑定的sql命令，在创建完cacheKey之后，就进入到CachingExecutor 类中的另一个query方法中。
7. CachingExecutor 的另一个query方法，真正执行query操作的是SimplyExecutor代理来完成的，接着就进入到了SimplyExecutor的父类BaseExecutor的query方法中。
8. 因为是第一次SQL查询操作，所以BaseExecutor的query方法会调用queryFromDatabase方法来执行查询。
9. BaseExecutor的queryFromDatabase方法，会调用SimplyExecutor的doQuery方法从数据库中查询数据。
10. SimplyExecutor的doQuery方法有两个子流程
    1. 调用prepareStatement方法，进行SQL查询参数的设置，也就是咱们最开始传递进来的参数，其值为1。
        1. 执行SimplyExecutor的prepareStatement方法。方法里
        2. 通过getConnection方法来获取一个Connection，
        3. 调用prepare方法来获取一个Statement，这里的handler类型是RoutingStatementHandler。
        4. RoutingStatementHandler的prepare方法调用的是PrepareStatementHandler的prepare方法，因为PrepareStatementHandler并没有覆盖其父类的prepare方法。
        5. PrepareStatementHandler的prepare方法调用的是BaseStatementHandler中的prepare方法。
        6. BaseStatementHandler中的prepare方法调用parameterize方法来设置SQL的参数值，实际调用的是PrepareStatementHandler中的parameterize方法。
        7. 而PrepareStatementHandler的parameterize方法调用的是DefaultParameterHandler中的setParameters方法。
        8. 到此子流程1完成，已经给Statement设置了最初传递进去的参数了。
    2. 调用handler.query方法会进行实际的SQL查询操作和结果集的封装（封装成Java对象）。
        1. 调用RoutingStatementHandler的query方法，实际调用另一个query方法。
        2. query方法内将statement强转成PreparedStatement。
        3. 调用PreparedStatement的execute方法，执行SQL查询操作。
        4. 调用ResultSetHandler的handleResultSets方法，处理结果。
        5. 实际会调用DefaultResultSetHandler的handleResultSets方法，封装返回值，将查询结果封装成Object对象。
        6. handleResultSets方法内，调用ResultSet的包装类ResultSetWrapper的getFirstResultSet方法，获取第一个ResultSet，同时获取数据库的MetaData数据，包括数据表列名、列的类型、类序号等，这些信息都存储在ResultSetWrapper类中了。
        7. 然后调用handleResultSet方法来来进行结果集的封装。
        8. handleResultSet内调用handleRowValues方法来进行值的设置。
        9. handleRowValues调用handleRowValuesForSimpleResultMap方法封装数据。
        10. handleRowValuesForSimpleResultMap方法调用getRowValue方法。
        11. getRowValue方法先调用createResultObject为新创建的对象，数据表对应的类。
        12. getRowValue方法然后调用applyAutomaticMappings方法把ResultSet中查询结果填充到JavaBean中，metaObject中包含了resultObject信息。
        13. applyAutomaticMappings方法进行for循环调用，因为user表中总共有7项，所以也就调用7次。
        14. 循环里调用Mapping.TypeHandler类的getResult方法，会获取查询结果值的实际类型，比如我们user表中id字段为int类型，那么它就对应Java中的Integer类型，然后通过调用statement.getInt("id")来获取其int值，其类型为Integer。
        15. 然后调用MetaObject类的setValue方法会调用到Java类中对应数据域的set方法，即把获取到的Integer值设置到Java类中的对应字段，这样也就完成了SQL查询结果集的Java类封装过程。

#### 利用Spring特性进行整合

https://blog.csdn.net/Munger6/article/details/90319317

​		整合的目的是将对象交给容器管理，便于容器之间依赖的解耦；对象重用，性能友好。

1. spring在初始化的过程中，会去创建AuthUserServiceImpl类。

2. 创建完成之后，会进行属性赋值，AuthUserMapper这个mybatis接口就是AuthUserServiceImpl的一个属性。

3. 根据这个mapper的名字从spring的BeanFactory中获取它的BeanDefinition，再从BeanDefinition中获取BeanClass，AuthUserMapper对应的BeanClass就是MapperFactoryBean，是在创建MapperScannerConfigurer对象的时候设置的。

4. 创建MapperFactoryBean对象，创建完成之后，需要对属性进行赋值。哪些属性需要赋值呢是在创建AuthUserMapper所对应BeanDefinition对象的时候决定的，创建MapperScannerConfigurer对象时，其中有一个属性就是SqlSessionFactoryBean。根据标签进行实例化：

    ```
    <bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean">
        <!-- 加载数据源 -->
        <property name="dataSource" ref="dataSource"/>
        <property name="mapperLocations" value="classpath*:mappers/*Mapper.xml"/>
    </bean>
    ```

5. MapperFactoryBean对象的属性设置完成之后，就调用它的getObject()方法，来获取authUserMapper对应的实现类。

6. 最后返回的就是一个使用jdk的动态代理创建出来的代理类MapperProxy，实际就是InvocationHandler的实现类。

7. 程序在调用authUserMapper对象的某个方法的时候，就会调用到MapperProxy对象的invoke()方法，去完成对数据库的操作。

## MyBatis Plus

​		EntityWarpper条件构造器

## Redis

### Redis简介

​		Redis是key-value类型的内存数据库，操作为纯内存操作，用定期异步flush到硬盘的方式进行保存。value提供多种数据类型，支持事务，两种持久化方式，多种集群模式。常用作缓存、分布式锁。

### 底层实现机制

​		redis是纯内存操作，采用单线程工作模型，为非阻塞I/O多路复用机制。

​		redis是纯内存操作，速度快；数据结构及对数据的操作都比较简单；采用单线程，避免了不必要的上下文切换开销。传统的并发模型是单核CPU，每个I/O流都由一个新的线程管理，多线程会造成频繁的上下文切换，降低性能。而redis的单线程非阻塞I/O多路复用机制，由单个线程跟踪每个I/O流的状态来管理多个I/O流，服务端的I/O多路复用程序将客户端在操作时产生的不同事件类型的socket放入队列中，由文件事件分派器依次取出，转发到不同的事件处理器中。

#### 非阻塞I/O多路复用模型

​		多路指多个网络连接，复用指复用同个线程。服务端的I/O多路复用程序将客户端在操作时产生的不同事件类型的socket放入队列中，本质上通过系统内核缓冲I/O数据，从而同时监控跟踪每个I/O流的状态来管理多个I/O流，空闲时将当前线程阻塞，有一或多个I/O事件时，则从阻塞中唤醒，程序轮询一遍所有的流（非epoll），由文件事件分派器依次取出就绪的流，转发到不同的事件处理器中。避免大量无用操作，让单个线程高效的处理多个连接请求，尽量减少网络I/O的时间消耗。且不必创建和维护线程或进程，减小系统的开销。

**select**：每次调用时，需将fd_set集合从用户态拷贝到内核态，在内核态遍历所有fd_set，内核对被监控的fd_set集合有大小限制，为1024.

**poll**：数据结构为pollfd_set，无大小限制。

**epoll**：最大连接数没有限制，采用事件通知的方式，每当fd就绪时，系统注册的回调函数就会被调用，随即将fd放到readyList中。

### 配置

**port:6379**：指定访问redis服务的端口

**bind:0.0.0.0**：指定redis绑定的主机地址，配置为 0.0.0.0表示为外网也可以访问。

**timeout**：指定客户端连接redis服务器时，当闲置的时间为多少时关闭连接。

**loglevel**：指定redis数据库的日志级别，常用的日志级别有debug、verbose、notice、warning，不进行修改的情况下默认的是notice。

**save**：指定redis数据库s时间内有c次更新操作（insert、update、delete和）时就把缓存中的数据持久化到本地磁盘。

**dir**：指本地数据文件存放的目录

**requirepass**：指定redis的访问密码

**maxmemory**：指定redis的最大内存。redis在启动时会把数据加载到内存中，当到达最大内存时，会自动清除已经到期和即将到期的key值 9

**appendonly**：指定redis是否开启日志记录功能。由于redis利用save命令异步的方式更新数据到本地库，所以不开启日志记录功能，可能会导致在出现生产事故时，导致部分数据未更新到本地库。

**vm-enabled**：指定redis是否启用虚拟内存机制

### 架构

#### 主从架构

​		当单台服务器出现如硬盘故障等问题，使得持久化到硬盘中的数据丢失，为避免单点故障，可将redis数据库复制多个副本部署在不同的服务器上。主数据库master可进行读写操作，从数据库slave只负责读操作。一个数据库只可有一个主数据库，一个主数据库可有多个从数据库。slave node主要用作横向扩容，做读写分离，提高读操作的吞吐量。

##### 流程

​		slave启动后，向master发送sync命令，master接收到sync后在后台保存快照RDB，并将保存快照期间接收的命令缓存起来，随后将快照和缓存的命令一同发给slave，slave将其存盘并加载到内存，依据快照和命令来与master保持同步，之后master每收到一个命令就异步发送给slave。当master进行写操作导致数据变化时，自动将数据同步给slave。slave中的key不设过期时间，当master中的key过期了，或者被LRU之类的机制淘汰了，则发送del命令给slave。

#### 主从架构+哨兵机制

​		哨兵使用流言协议gossipprotocols监控redis的主、从数据库是否正常运行，若master出现故障，使用投票协议agreement protocols决定是否执行自动故障迁移、及选择哪个slave作为新master。实现自动化的系统监控和故障恢复功能。

##### 优缺点

​		可保证redis的高可用。但每个redis实例都是全量保存，浪费内存。

##### 主从切换过程

1. slave leader升级为master

2. 其他slave修改自身为新master的slave
3. 客户端修改连接
4. 若旧master重启成功，转为新master的slave。

##### 宕机规则

​		每个哨兵向其他哨兵、master、slave定时发送消息以确认对方是否活着，若对方在指定时间内未回应，则主观认为其宕机。

**sdown**：只要有一个哨兵认为某master宕机，则判为主观宕机subjective down。

**odown**：当半数以上的哨兵均认为某master宕机，则判为客观宕机objective down。此时若多数哨兵均允许主备切换，则按照一定的vote规则，选出某个slave执行主备切换转为master，并自动修改相关配置。

##### 主备切换选举规则

1. 按slave priority排序，越小则优先级越高。
2. 若slave priority相同，则比较replica offset，offset越靠后代表复制的数据越多，优先级就越高。
3. 若以上条件均相同，则选择run id较小者。

##### 启动

​		虽然哨兵是一个单独的可执行文件redis-sentinel，但实际上它只是一个运行在特殊模式下的redis服务器，你可以在启动一个普通redis服务器时通过给定--sentinel选项来启动哨兵。

#### 集群架构

​		集群架构集成了主从和哨兵的功能，采用无中心结构，支持多个master，每个master可挂载多个slave。客户端与任一master直连。每个redis需开放两个端口号，如6397，则16379将作为集群总线，用来进行节点间的通信，用作故障检测、配置更新、故障转移授权。

##### 优点

​		使用哈希槽算法，分布式存储，每台机器redis存储不同的内容，节约内存。当master增减时，将其他master的hash slot移动部分过来或者将该master的hash slot移动到其他master上，移动简单成本低。

##### 节点宕机判断

​		每个节点均有该集群所有master和slave的信息，相互通过ping-pong判断节点是否可连接，内部使用二进制协议优化传输速度和带宽。当半数以上的节点去ping一个结点时没得到回应，集群则认为该节点宕机，则去连接它的备用节点。

##### 集群fail判断

1. 半数以上master挂掉，无论是否有slave。
2. 某master挂掉且当前master没有slave。
3. 某master及其slave全部挂掉。

##### 选举机制

​		master宕机后，slave发现自己的master变为fail，发起选举申请成为master，集群中所有master参与投票，半数以上master投出ack则成为新master，广播pong通知其他节点。master进入fail后有一定延迟确保fail状态在集群中传播，slave才发起投票，否则其他master尚未意识到fail则可能拒绝投票。

##### 主备切换选举规则

1. 网络连接正常
2. 5s内回复过INFO命令
3. 10*down-after-milliseconds内与master连接过
4. slave priority较小者
5. replica offset较后者
6. run id较小者

### 数据类型

**String**：get/set/decr/decrby/incr/incrby/setnx存在则返回0/setex同时设过期时间setex key seconds value

**Hash 字典**：哈希表+链地址法解决哈希冲突。结构化的对象（不能嵌套其他对象），可操作其中的某个字段。可用于单点登录，利用该数据结构存储用户信息。hget/hset/hgetall

**List 双端链表**：len属性。可用于粉丝列表、评论列表等，lrange命令为从某个元素开始读取多少个元素，可基于list实现分页查询。lpush/rpush/lpop/rpop/lrange

**Set**：可用于去重，集群部署时，若用JVM自带的set去做去重，需要做全局去重，再起一个公共服务。利用交集、并集、差集等，可计算共同爱好、全部喜好、独有喜好、共同好友等。spop/sadd/sunion/sinterstore

**ZSet(Sorted Set)**：底层实现有跳跃表skiplist+字典 / ziplist。有权重参数Score，可自定义排序规则，集合中的元素按照Score进行排列。可用于做排行榜、取TopN、延时任务、范围查找。zadd/zcard/zrange

**动态字符串SDS**：char[]数组+len属性+free属性（记录数组中未使用的字节数），可直接获取长度，防止溢出。

#### ZSet的实现

##### ziplist实现zset

​		ziplist编码的有序集合使用紧挨在一起的压缩列表节点来保存。第一个节点保存member，第二个节点保存score。集合元素按score从小到大的顺序排列。

##### 跳跃表skiplist+字典实现zset

​		skiplist编码的有序集合底层为zset结构体，一个zset由一个跳跃表和一个字典组成。跳跃表按score从小到大的顺序保存所有集合元素。字典保存从member到score的映射关系。同时使用两种数据结构，使得查找member对应的score值复杂度为O(1)，跳跃表在链表的基础上增加了跳跃功能，使得查找元素的时间复杂度为O(logN)。至于为什么不用RBT实现，因为跳跃表实现简单效率也很高。

##### 跳跃表

​		跳跃表是一种有序的数据结构，通过在每个节点中维护多个指向其他节点的指针，从而达到快速访问节点的目的。表中的节点按照分值大小进行排序。

###### 结构

​		由多层结构组成。每一层都是一个有序的链表，至少包含两个节点head+nil，排列顺序为由高层到底层。链表中的节点均含两个指针，一个指向同一层的下一个节点，另一个指向下一层的同一个节点。所以上一层的元素是当前层的元素的子集，最底层的链表包含了所有元素。

###### 操作过程

1. 搜索：从最高层的链表节点开始，若比当前节点大且比当前层的下一个节点小，则前往与下一层的当前节点的下一个节点进行比较，以此类推，找到则返回，若直到最底层的最后一个结点仍未找到，则返回空。

2. 插入：确定插入的层数k，将新元素分别从底层逐层插入到k层。

3. 删除：删除各层链表中包含指定值的节点，若删除后该层只剩头尾两节点，则删除该层。

### 存储策略

​		redis持久化即将内存中的数据写入到硬盘中，以便备份重用数据。支持快照RDB和追加文件AOF两种持久化方式，也可同时关闭或同时开启，这样便有4中持久化策略。

#### RDB

​		默认存储策略。将整个Redis DataBase的内存快照保存到本地，或者复制到其他机器上，默认保存在安装目录下的dump.rdb文件中，该文件保存了内存中所有的堆、栈等的信息，可以根据信息得知哪块内存空间开销大，从而解决内存溢出问题。配置文件中设置如save 900 1，代表每900s内发生1次变化则保存1次快照，每保存一次则重置时间重新计时，可以设置多条，多个条件之间相互独立。

#### AOF

​		将每一个修改操作写入日志文件，每次启动将读取日志中的内容，默认没有开启。有三种AOF方式：

1. always：每次修改都写入AOF。
2. everysec：每秒钟同步一次，多个命令一次写入。
3. no：由操作系统决定何时同步。

**比较RDB和AOF**：RDB只代表了某一时刻redis的数据，实时性不好，可能会丢失部分数据，数据恢复速度快，若文件过大，可能会导致提供的服务暂停几秒，适合做冷备份；AOF的实时性更好，写入性能比较好，可保证数据不丢失，但AOF文件更大，数据恢复速度较慢。综上，AOF可保证数据不丢失，是作为恢复数据的首选，同时用RDB做不同程度的冷备份，可在AOF文件丢失或损坏时，进行快速的数据恢复。

#### 序列化

​		序列化的目的是为了对象可以跨平台存储和进行网络传输，存储和网络传输都需将对象的状态保存成一种跨平台识别的字节格式，其他平台才可根据字节信息解析还原对象的信息。

**JdkSerializationRedisSerializer**：默认序列化方式，JDK提供的序列化功能，需事先Serializable接口，占用内存较大，应用工具查看k-v会乱码。

**Jackson2JsonRedisSerializer**：Jackson库提供的序列化为JSON字符串的功能，速度快，占用小，反序列化过程中此类的构造函数有一个类型参数，需提供对象的类型信息。

​		通过自定义配置类RedisConfig，替换掉默认的序列化方式。例如：

```
//key采用String的序列化方式：redisTemplate.setKeySerializer(stringRedisSerializer)

//value采用jackson序列化方式：redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);
```

#### 缓存过期策略

​		redis可以为key设置过期时间，对于过期的key，采用定期删除和惰性删除的方式。

**定时删除**：定时器监控，每100ms随机抽取key检查是否过期，若过期则删除，会导致很多key已到过期时间却没有删除，比较消耗CPU资源。

**惰性删除**：当获取key时，检查该key是否过期，若过期则删除。

**定时删除+惰性删除策略**：redis采用这种策略的缺点是，若定期删除未删掉的key，也没有去请求该key，则惰性删除不生效，导致redis内存占用越来越高，所以引入了内存淘汰机制。

#### 内存淘汰机制

​		当redis中有大量的key，内存达到最大值时，将采用内存淘汰机制，当内存不足以容纳新写入数据时，有六种策略，若没有了已设置过期时间的key，执行volatile策略类似于noeviction。

**noeviction**：新写入操作会报错。

**allkeys-lru**：移除最近最少使用的key

**allkeys-random**：随机移除某个key

**volatile-lru**：移除最近最少使用的设置了过期时间的key

**volatile-random**：随机移除设置了过期时间的某个key

**volatile-ttl**：移除具有更早过期时间的key

#### 数据丢失问题

​		异步复制下数据还未复制到slave时，master就宕机了，导致数据丢失。

##### 解决方案

​		至少要有一个slave，若master不能给指定数量的slave发送数据，且slave超过给定时间没有返回ack消息给master，则直接拒绝客户端的写请求。

### 缓存

#### 分类

##### 本地缓存

​		量轻快速，随着JVM的销毁而结束，在多实例的情况下，各实例均保存一份缓存，不具有一致性。

##### 分布式缓存

​		在多实例的情况下，各实例共用一份缓存数据，具有一致性，但架构复杂，需额外保证服务的高可用。

###### 普通的分布式缓存策略

​		hash(key)%N，这样当其中一个服务器宕机或增删服务器时，rehash致使所有缓存失效，请求跑到后端，增大服务器压力，数据大规模迁移。

###### 一致性哈希算法

​		将整个hash空间0~2^32-1组成虚拟圆环，各服务器有其对应的值，对key进行hash取模得到哈希值，将key存入逆时针寻找遇到的第一个服务器。

​		优点是增删服务器时数据迁移较简单。缺点是数据可能扎堆分布在某个服务器上，若该服务器出现问题，对整个系统的影响依然较大。

​		针对分配不均的情况，可将服务器后面的ip或主机名后增加编号，生成多个虚拟节点，分配到虚拟节点上的数据实际上是分配到了该服务器上，以使数据尽可能均分。

###### 哈希槽算法

​		对每个key计算CRC16值，对16384取模，将这些key对应的hash slot分配给cluster中配置的master。

#### 实现

##### redis用作缓存

​		redis用作缓存的作用是提高性能和并发量。执行耗时久、结果不频繁变动的SQL时，将运行结果放入缓存中，后面的请求则先到缓存中读取，以提升响应速度。在并发量大时，若所有请求直接访问数据库，易造成数据库连接异常或服务宕机，使用redis作为缓冲，可使请求先访问redis，而不是直接访问数据库，以提高并发量。

###### 双写一致性

**强一致性**：不能使用缓存，因为无法完全避免不一致问题。

**最终一致性**：采用延时双删策略。先更新数据库，再删缓存，将缓存失效的信息发到MQ中，MQ不断重试让缓存失效，休眠大概1s后，再次删除缓存，淘汰这一段时间内缓存中的脏数据，保证缓存和数据库的一致性。否则会出现如下情况：

1. 先删缓存后更新数据库：A系统删除缓存，更新数据库的过程中，B系统查询缓存不存在，查询旧数据库得到旧值，然后缓存旧值，造成数据库和缓存不一致。
2. 先更新数据库后删缓存+数据库读写分离主从异步复制：A写系统更新数据库+删缓存后，数据库异步复制过程中，B读系统查询缓存不存在，然后缓存旧值，造成数据库和缓存不一致。

#### 缓存雪崩

​		缓存雪崩指缓存在同一时间内大面积失效，所有的请求均直接访问数据库，导致数据库在短时间内承受大量的请求而崩掉。

##### 原因

​		redis服务器宕机或者设置了相同的过期时间导致key同时失效。

##### 解决方案

1. 搭建redis集群保证高可用性。
2. 尽可能错开key过期时间；可在原过期时间上加一个随机值，防止集体同时失效。
3. 设置双缓存，A设过期时间，B不设，手动预热缓存，先读A若不存在则读B，同时异步开启一个更新线程同时更新A和B。
4. 加一层本地缓存，先查本地缓存再查redis。
5. 限流+降级，每秒只接受一定量的请求，多余的请求走降级组件。
6. 利用持久化机制恢复缓存。

#### 缓存穿透

​		缓存穿透指一直查询不存在的数据，正常来说数据查询先到缓存中查询，若key不存在或已过期，则到数据库中查询，并把查询结果存入缓存。若数据库中未查到，则不放入缓存，当一直查询不存在的数据时，且查询量很大，则会击穿数据库。

##### 解决方案

1. 当数据库中查询结果为空时，也在缓存中做一个标记，下次去缓存中查询时即可得知该数据为空。这意味着要设置更多的key占用更多的内存，所以过期时间最好设短些。
2. 采用拦截机制，如布隆过滤器，将所有可能的数据哈希到一个bitMap中，判断请求参数是否合法，拦截不存在的数据访问，合法时才进入后续逻辑，缺点是有一定的误识别率。
3. 上互斥锁，当缓存失效时，先获得锁，获得锁后再去请求数据库，若没得到锁，则休眠一段时间后重试。

#### 缓存预热

​		缓存预热指系统上线后，将相关的缓存数据直接加载到缓存系统中，可使用户在请求时直接查询事先被预热的缓存数据，避免先查询数据库再写入缓存。

##### 解决方案

​		写个缓存刷新页面，上线时手工操作或者自动加载，再加上定时刷新缓存。

#### 缓存降级

​		当访问量剧增，服务器响应慢或无响应时，非核心服务影响到了核心流程的性能，需要保证服务的仍可用，即便是有损的服务，可以进行缓存降级。目的是保证核心服务的可用，购物车、结算等服务无法降级。

##### 解决方案

​		根据关键数据进行自动降级，或配置开关实现人工降级。首先对系统进行梳理，找出需要保护和可降级的服务，可参考日志级别设置预案：

1. 一般：服务偶尔因网络问题或服务正在上线而超时，自动降级。

2. 警告：服务在一段时间内成功率在95%-100%间波动，自动降级或人工降级，并发送告警。

3. 错误：可用率低于90%时，或数据库连接池爆炸等访问量突然猛增到系统所能承受的最大阈值的情况，根据情况自动降级或人工降级。
4. 严重错误：因特殊原因发生数据错误，需紧急人工降级。

### 热key

#### 定位

1. 经验预估
2. redis-cli-hotkeys命令查询
3. 客户端收集统计数据

#### 减压

1. 服务端缓存：将热点数据缓存至服务端的内存中，利用ehcache或者HashMap，热key被加载到系统的JVM中，而不会走redis层。若发生服务端缓存和redis缓存数据不一致的情况，可利用redis自带的消息通知机制，对热key建立一个监听，当热key有更新操作时，缓存也随之更新。

2. 备份热key：redis集群中包含了16384个哈希槽，使用公式CRC16(key)%16384计算key属于的哈希槽。将热key加上一个随机值，使其随机分配到redis的其他节点中，使得同个key分布在不同的机器上，访问热key时请求不会全部命中到一台机器上。这些随机值可以是一个有限列表里面随机，请求的时候再随机加上一个列表中的值，这样便不会不命中。

### 并发

#### 并发竞争key

​		当多个子系统同时对同个key进行操作，若不要求顺序，则可使用redis实现分布式锁解决，若有顺序要求，则可在value上加个时间戳，或者利用队列将set方法变成串行化访问。不用本地事务的原因是当部署了集群时，若一个事务涉及到多个key且不一定存储在同一个redis-server上。

#### 分布式锁

​		使用redis实现分布式锁性能好，实现简单，但容易造成死锁。memcache同理可实现。

1. 不要求顺序：获取锁时，使用setnx命令加锁，并为锁添加一个超时时间，超过该时间自动释放锁，解决死锁。delete key则释放锁。
2. 要求顺序：加个时间戳。例如，假设ABC三系统需按顺序将key设置为valueA valueB valueC，假设B先抢到锁，将key设为valueB 3:05，接下来A抢到锁发现自己的时间戳早于缓存中的时间戳，则不做set操作。

### 事务

​		redis使用命令实现事务功能，multi开始事务、exec执行事务、discard取消事务，watch监视key，但redis没有在事务上增加任何维持原子性的机制，单个redis命令才是原子性操作，以上这些命令相当于一个打包的批量执行脚本，并非原子化操作，中间某条指令的执行失败并不会导致之前已执行指令的回滚，也不会造成后序未执行指令的取消，综上。

### Sentinel

​		Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。

1. 丰富的应用场景：Sentinel承接了阿里巴巴近10年的双十一大促流量的核心场景，例如秒杀，即突发流量控制在系统容量可以承受的范围；消息削峰填谷；实时熔断下游不可用应用，等等。

2. 完备的监控功能：Sentinel同时提供最实时的监控功能，您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。

3. 简单易用的扩展点：Sentinel提供简单易用的扩展点，您可以通过实现扩展点，快速的定制逻辑。例如定制规则管理，适配数据源等。
    Sentinel分为两个部分:

4. 服务端基于Spring Boot开发，打包后可以直接运行，不需要额外安装Tomcat等应用容器。

5. Java客户端不依赖任何框架，能够运行于所有Java运行时环境，同时对Spring/Spring Boot环境也有较好的支持。服务端基于Spring Boot和Spring Cloud开发，打包后可以直接运行，不需要额外安装Tomcat等应用容器。

#### 动态数据源架构设计理念

##### 管理后台

​		管理后台主要用于可视化配置限流规则、熔断规则。新增流控规则的具体参数：资源名、针对来源、阈值类型（QPS/线程数）、单机阈值、是否集群、其余高级选项。

##### 限流熔断规则数据源

​		用于存储限流熔断规则的数据容器，在 Sentinel 中对应动态数据源这个概念，动态数据源包含两层含义：

1. 数据容器：指存储熔断、限流等规则配置的数据库，例如关系型数据库、Zookeeper等等，在实际生产过程中需要选用支持持久化功能的数据库，否则程序一重启，配置规则就会丢失，显然是不能接受的。
2. 动态：主要强调的是配置规则的更改能动态及时生效，引入 Sentinel 限流 SDK 的应用程序在不需要重启的情况下动态感知配置规则发生变化并立即生效。Sentinel 目前对 apollo、consul、etcd、nacos、redis、spring-clould-config、zookeeper 等进行了适配支持。

##### 应用程序

​		希望通过 Sentinel 提供的限流、熔断功能对应用程序加以保护，需要引用 Sentinel 相关的 SDK，根据采集的调用信息判断当前是否符合限流规则。

1. 在后台管理系统sentinel-dashboard配置规则。
2. 规则存入动态数据源ZooKeeper集群
3. 应用程序引入Sentinel相关SDK（sentinel-core+sentinel-datasource-extension），订阅Zookeeper指定路径，即限流、熔断等配置规则的路径。
4. 当订阅的动态数据源中的数据发生变更时，推送到客户端。

#### 改造思路

1. 从官方示例寻找改造思路。从官方的文档中可获悉官方自带的后台管理系统sentinel-dashboard只支持将限流、熔断等限流配置规则存储在内存中，一旦后台管理系统重启，配置的熔断规则将全部丢失，所以在生产实践过程中需要对 sentinel-dashboard 进行一定的改造，引入动态数据源，例如 Zookeeper，对限流等配置进行持久化存储。

2. 我们基于zookeeper构建Sentinel动态数据源。看一下官方提供的Demo，在sentinel-demo-zookeeper-datasource/src/main/java/com.alibaba.csp.sentinel.demo.datasource.zookeeper包下有两个类：ZookeeperConfigSender和ZookeeperDataSourceDemo。

##### 限流熔断等规则存储

1. ZookeeperConfigSender类的主要作用是将配置写入到 zookeeper 中。先将限流规则持久化到 Zookeeper 中，充当的角色与 sentinel-dashboard一致，故这个类为我们改造后台管理系统带来很大的启发，即可以通过 zookeeper 存储 sentinel 限流规则，从 demo 示例可以看出限流规则在 zookeeper 中的目录结构，路径为 /{groupId} / {dataid} ，该节点的 value 值存储 json 字符串，存储所有的限流规则。

    ```
    ZookeeperConfigSender：
    配置存储规则：remoteAddress、groupId、dataId、rule（Json字符串形式）
    zkClient=CuratorFrameworkFactory.newClient(remoteAddress,new ExponentialBackoffRetry(SLEEP_TIME,RETRY_TIMES));
    zkClient.start();
    path=getPath(groupId,dataId)
    Stat stat=zkClient.checkExists().forPath(path);
    if(stat==null) {	
    	zkClient.create().creatingParentContainersIfNeeded()
    	.withMode(CreateMode.PERSISTENT).forPath(path,null);
    }
    zkClient.setData().forPath(path,rule.getBytes());
    ```

2. 通常基于 zookeeper 的开发，主要是规划好目录结构。

    1. 在zookeeper 中创建一个根节点，例如 /sentienl 用来表示限流相关的根目录。
        1. groupId 通常为一个独立的应用名称，例如应用的 appId。
        2. dataId 通常为配置类型，例如限流规则、熔断规则、热点规则等类别。例如限流规则使用 /flowRule ，熔断规则使用 /degradeRule，其 value 值使用 json 存储，将该应用下的所有限流规则用一个 json 对象表示，其存储格式类似于 [{},{}]。

##### 客户端动态感知配置

1. 需要客户端能动态感知规则的变化，使得配置规则实时生效。我们依然先来看一下官方Demo的核心代码，这里尽管引入 groupId 与 dataId 的概念是方便与 nacos 进行切换，但就算不切换，基于 zookeeper 的编程，这种目录规划是非常有必要的。

    1. 创建 ZookeeperDataSource，每一个 ZookeeperDataSource 负责监听一个节点。
    2. 需要调用 FlowRuleManager 的 register2Property 方法将数据源关联的数据注册到 FlowRuleManager 中，方便 Sentinel 内核根据数据源中存储的限流熔断等规则进行工作。

    ```
    new ZookeeperDataSource(remoteAddress,groupId,flowDataId,source->JSON.parseObject);
    FlowRuleManager.register2Property(dataSource.getProperty());
    ```

2. 客户端在启动的时候会调用 FlowRuleManager 相关方法加载限流相关的配置，配置规则发生变化后，客户端动态感知的关键在于 ZookeeperDataSource 的实现中，在构建 ZookeeperDataSource 时会监听 /groupId/dataId 节点，即存放限流配置的节点，一旦数据发生变化，就会通知到客户端，从而调用 loadConfig 重新更新Sentienl 客户端的限流配置，从而实现配置实时生效。

    ```
    initZookeeperListener(){
    	this.listener = new NodeCacheListener(){
    		@Override
    		puclic void nodeChanged(){...}
    	}
    	this.nodeCache = new NodeCache(this.zkClient,this.path);
    	this.nodeCache = getListenable().addListener(this.listener);
    	this.nodeCache.start();
    }
    ```

#### 动态数据源实现方案

​		sentinel-dashboard 里提供了简单的机器发现，并且内置了 sentinel 客户端之间、sentinel 客户端与 sentinel-dashboard 之间的通讯协议，具体由 sentinel-transport 模块实现，目前提供了基于 http 与 netty 的实现方式，故能将 sentinel-dashboard 内存中的配置信息推送到客户端，从而使客户端根据配置进行限流与熔断。

##### 将配置规则存储在Zookeeper中

1. 增加流控规则的后台处理入口为：17和18行

    ```
    @PostMapping("/rule")
    public Result<FlowRuleEntity> apiAddFlowRule(HttpServletRequest request, @RequestBody FlowRuleEntity entity){
        AuthUser authUser = authService.getAuthUser(request);
        authUser.authTarget(entity.getApp(), PrivilegeType.WRITE_RULE);
    
        Result<FlowRuleEntity> checkResult = checkEntityInternal(entity);
        if(checkResult!=null){
            return checkResult;
        }
        entity.setId(null);
        Date date = new Date();
        entity.setGmtCreate(date);
        entity.setModified(date);
        entity.setLimitApp(entity.getLimitApp().trim());
        entity.setResource(entity.getResource().trim());
    
        entity = repository.save(entity);
        publishRules(entity.getApp());
    }
    ```

2. 将数据存储在 zookeeper 中，其关键是设计好各个项目如何有组织有条理的在 zookeeper 中进行组织。/flow的value值，使用[{}]json字符串的方式存储该appId下所有的限流规则。这样相关管理人员可以直接在 sentinel-dashboard 中配置限流规则，即按照应用为维度进行存储，每一个应用再按照维度，例如限流、熔断、热点、集群等维度进行配置，每一分类节点的值存储的是所有的配置，使用 [{},{}] 这种JSON格式进行存储。

    ```
    /
    	/dubbo
    	/sentinel
    		/{appId1}
    		/{appId2}
    			/flow
    			/degrade
    			/param
    ```

##### Sentinel 客户端规则加载封装

​		我们基于SpringBoot进行客户端加载的实现。利用SpringBoot的事件机制，在Spring容器初始化后，开始加载 zookeeper 中的配置。其实现思路是读取 zookeeper 中的 /sentinel 下所有的子节点，然后并依次遍历其子节点(appid)，然后依次读取 flow（限流）、degrade(熔断)等配置，并调用Sentinel的相关API完成加载。伪代码：

1. 基于 Spring ApplicationReadyEvent 事件，实现限流规则的加载。
2. 创建 ZookeeperDataSource 创建动态数据源。
    并调用 Sentinel 提供的相关 API 完成限流规则的加载。

```
public class SentinelLoadApplicationListener implements ApplicationListener<ApplicationReadyEvent> {
    @Override
    public void onApplicationEvent(ApplicationReadyEvent applicationReadyEvent) {
        String appId = "sentinelDemoAppId";
        String groupId = "/sentinel";
        String dataId = "/"+appId;
        String zkAddress = "";
        List<String> nodeConfigs = findConfigNodesByAppId(appId);
        for(String nodeType : nodeConfigs){
            if ("flow".equals(nodeType)){
                ReadableDataSource<String, List<FlowRule>> flowRuleDataSource = 
                new ZookeeperDataSource<>(zkAddress,groupId,dataId,source->
                JSON.parseObject(source,new TypeReference<List<FlowRule>>(){}));
                FlowRuleManager.register2Property(flowRuleDataSource.getProperty());
            }
            else if("degrade".equals(nodeType)){
                ReadableDataSource<String, List<FlowRule>> degradeRuleDataSource = 
                new ZookeeperDataSource<>(zkAddress,groupId,dataId,source->
                JSON.parseObject(source,new TypeReference<List<FlowRule>>(){}));
                DegradeRuleManager.register2Property(degradeRuleDataSource);
            }
        }
    }
}
```

### 项目中遇到的问题

Q. 项目中使用redis遇到了什么问题

A. 热点数据太猛，而此时带宽已满，访问不到redis客户端，跑去操作数据库，连接也不足。发现了这个问题后我们添加了一层本地缓存。